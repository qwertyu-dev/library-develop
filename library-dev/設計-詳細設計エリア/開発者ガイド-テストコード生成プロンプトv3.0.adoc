= Pythonテストコード生成prompt
pythonモジュールに対するテストコード生成プロンプト(プロジェクト標準)を示します。
原則生成は以下手順に從い対応してください。

このプロンプトはプロジェクトで必要な最低限の品質段階のテストコードを生成します。担当者によりテストコードの追加が必要であったり、エラーとなるテストコードやテストコードにより判明したテスト対象モジュールの改修を行う必要があります。

[IMPORTANT]
====
* 最低限必要なテストイベントレベルの生成でしか無い
* 生成テストコードに対し,担当者によりテストコードの追加・修正が必要な前提
====

---

.prompt: 前提の確認
====
<role>
あなたはPython実装における世界的に有名な方で、設計、実装、テストなどあらゆるタスクに精通しています。実装するコードやテストで人々を魅了しています
</role>

以下の作成ルールと提供されたサンプルコードに従って、[クラス名]の[メソッド名]のためのpytestベースのテストコードを作成してください。 +
サンプルコードの形式と構造を模倣し、それに準拠したテストコードを作成することが重要です。 +

## テスト対象コードに対するテストコード作成の進め方 +
StepByStepで進めます、一度に進めず各stepで立ち止まってください +

<step>
    <step0>テストコードサンプルでの構造理解</step0>
    <step1>テスト対象コードの理解</step1>
    <step2>テスト対象コードに対するC0の考察、全てのメソッド、考察結果は説明の上でテーブル形式で出力</step2>
    <step3>テスト対象コードに対するC1の考察、全てのメソッド、考察結果は説明の上でテーブル形式で出力</step3>
    <step4>テスト対象コードに対するC2の考察、全てのメソッド、考察結果は説明の上でテーブル形式で出力</step4>
    <step5>テスト対象コードに対するC1とディシヨンテーブル(DT)の組み合わせの考察、全てのメソッド、考察結果は説明の上でテーブル形式で出力</step5>
    <step6>テスト対象コードに対する境界値テスト（BVT）の考察、全てのメソッド、考察結果は説明の上でテーブル形式で出力</step6>
    <step7>テストケースの優先順位付け、優先度の高い順に実行する計画を立てる</step7>
    <step8>リスクベースのテスト、リスクの高い部分に対するテストケースを重点的に考察する</step8>
    <step9>テストデータの準備を考察し、必要なデータを準備する計画を立てる</step9>
    <step10>テスト対象コードに対するテスト全体鳥瞰としてmindmap作成しアウトラインtree構造で出力する、日本語、必ずメソッド単位にC0,C1,C2,DT,BVTの区分を付与する</step10>
    <step11>テスト対象コードに対するテスト全体鳥瞰としてmindmap妥当性評価、アウトラインtree構造で出力する、日本語、必ずメソッド単位にC0,C1,C2,BVTの区分を付与する、アウトラインの縦棒に相当する位置は揃えてください</step11>
</step>

全てのメソッドに対して以下繰り返します +
メソッド単位に作成します、メソッド名を指定しその単位で立ち止まってください
<メソッド毎にstep>
    <step12>テスト対象コードに対するC0テストコード作成</step12>
    <step13>テスト対象コードに対するC0テストコード妥当性分析</step13>
    <step14>テスト対象コードに対するC1テストコード作成、ディシジョンテーブル(DT)も作成</step14>
    <step15>テスト対象コードに対するC1テストコードとディシジョンテーブル(DT)の対応関係確認</step15>
    <step16>テスト対象コードに対するC2テストコード作成</step16>
    <step17>テスト対象コードに対するC2テストコード妥当性分析,C2での条件組み合わせMatrixを出力して、考察が妥当であるかの判断をフィードバックしてください</step17>
    <step18>テスト対象コードに対する境界値テスト（BVT）コード作成</step18>
    <step19>テスト対象コードに対する境界値テスト（BVT）コード妥当性分析と実装・未実装確認</step19>
    <step20>
        - メソッド単位でClassにします
        - C0,C1,C2,DT,BVTのテストコードをまとめて、1つのテストコードにします
        - テストコード作成手順ルールを思い出してください
        - step12〜step19での考察コードを絶対に漏らさず拾ってください
        - step12〜step19での考察コードは再編せず1ケース毎に記載してください
        - C1のディシジョンテーブルをテストClassのdocstringに追加してください
        - 境界値検証ケース一覧と実装状況をテストクラスのdocstringに追加してください
        - テーブルの縦棒位置は揃えてください
    </step20>
    次のメソッドに対する検証を行います、対象メソッド名を確認しましょう<step12>に戻ります
</メソッド毎にstep>

## 境界値検証ケース一覧作成ルール: +
- 各入力パラメータに対して以下の境界値を考慮してください： +
    1. 最小有効値 +
    2. 最小有効値の直前の値 +
    3. 最小有効値の直後の値 +
    4. 通常の値 +
    5. 最大有効値の直前の値 +
    6. 最大有効値 +
    7. 最大有効値の直後の値 +
- 特殊なケースも考慮してください： +
    - null値（適用可能な場合） +
    - 空の値（文字列、リスト、辞書など） +
    - 極端に大きな値や小さな値 +
    - 型変換が必要なケース +
- 各境界値ケースに一意のID（例：BVT_001, BVT_002）を割り当ててください +
- 境界値ケースの一覧を表形式で作成してください。表には以下の列を含めてください： +
    - ケースID +
    - 入力パラメータ +
    - テスト値 +
    - 期待される結果 +
    - テストの目的/検証ポイント +

## 境界値検証ケース実装状況確認ルール: +
- 境界値検証ケース一覧の各ケースがテストコードで実装されているか確認してください +
- 実装状況を以下のように分類してください： +
    - 実装済み、実装済の場合はのケースで実施しているかの情報(BVTだけでなく他のカテゴリ(C0,C1,C2,DT)及びケース) +
    - 未実装 +
    - 一部実装（複合的なケースの場合） +
- 実装状況を境界値検証ケース一覧の表に「実装状況」列として追加してください +
- 他のカテゴリで実施してる場合は、対応するテストケース（メソッド名とパラメータ）を明記してください。
- 未実装または一部実装のケースがある場合、その理由と対応方針を記述してください +
注記：

## テストクラスdocstring追加ルール: +
- テストクラスのdocstringに以下の情報を追加してください： +
    - 境界値検証ケース一覧（表形式） +
    - 境界値検証ケースの実装状況サマリー +
    - 未実装または一部実装のケースに関する注記 +

## テストコード作成手順ルール: +
テストシナリオの設計: +
- [メソッド名]の機能を分析し、C0（命令網羅）、C1（分岐網羅）、C2（条件網羅）、DT(ディシジョンテーブル)、BVT（境界値テスト）の観点でテストシナリオを考えてください。 +
- 考えたテストシナリオをMindmap形式で表現し、C0、C1、C2、DT、BVTの区分を明示してください。 +

## テストクラスの作成ルール: +
- Test_[クラス名]_[メソッド名]という名前のテストクラスを作成してください。 +
- クラスのdocstringに、作成したC0、C1、C2、DT、BVT区分を明示したMindmap outlineを全て記載し全体見通しを明確にしてください。 +

## テストメソッドの実装ルール: +
- test_[メソッド名]_[テストカテゴリ]_[テストシナリオ概要]でメソッドをテストする関数を作成してください +
    - テスト区分： ut or it +
    - テストカテゴリ： C0 or C1 or C2 or DT or BVT +
- C0、C1、C2、BVTの各カテゴリに対応するテストメソッドを実装してください。+ 
- 各テストメソッドには以下の情報を含むdocstringをtest_docという変数に格納するよう記述してください： +
    - テスト区分（正常系 or 異常系/UT or IT） +
    - テストカテゴリ（C0 or C1 or C2 or DT or BVT） +
    - テストシナリオの説明 +
- テストメソッド内では、適切なアサーションを使用して期待される動作を検証してください +
- サンプルコードと同様のコメントを付与してください +
- 他のテストカテゴリーテストでカバー済のものはその旨を記載してください +

## C1テストとディシジョンテーブル(DT)の連携ルール: +
- C1テストの各ケースに対応するディシジョンテーブル(DT)の行を作成してください。 +
- テストメソッド名にディシジョンテーブルの行番号を含めてください（例：test_method_name_C1_DT_01_condition_description）。 +
- テストメソッドのdocstringにディシジョンテーブルの該当行の内容を記載してください。 +

## 境界値テスト（BVT）の実装ルール: +
- 入力パラメータの境界値（最小値、最大値、境界付近の値）を特定し、テストケースを作成してください。 +
- 境界値を超える値での動作も検証してください。 +
- 特殊な入力（null値、空文字列、全て同じ値の配列など）についてもテストを行ってください。 +

## ログ出力ルール: +
- 各テストメソッドの冒頭で、テスト関数名を含むログメッセージを出力してください。 +
- テストの重要なステップでログメッセージを出力し、テストの流れを追跡可能にしてください。 +

## 例外処理とエッジケースルール: +
- 必要に応じて、例外が発生するケースのテストを含めてください。 +
- エッジケース（境界値、特殊な入力など）についても考慮し、テストを作成してください。 +

## コードスタイルルール: +
- PEP8に準拠したコードスタイルを使用してください。 +
- 適切な変数名とコメントを使用し、コードの可読性を高めてください。 +

## 注意事項: +
- 実際の環境で再現が難しいテストケース（例：メモリ不足）については、コメントアウトし、その理由を説明してください。 +
- テストコードは、提供されたサンプルコードの形式と構造に厳密に準拠してください。特に、クラスのdocstring、テストメソッドの命名規則、ログ出力の形式などに注意してください。 +
- このプロンプトとサンプルコードに従ってテストコードを作成してください。サンプルコードの構造と形式を模倣することが重要です。不明な点がある場合は、質問してください。 +

## ディシジョンテーブルフォーマット +
以下の構成Matrixを作成してください,４つの象限で構成されます。 +

1.条件記述部 +
考慮すべき条件を列挙して記述する部分です。条件を記述するので条件記述部と呼ばれます。 +

2.動作記述部 +
考慮すべき動作（出力結果）を列挙して記述する部分です。動作を記述するので動作記述部と呼ばれます。 +

3.条件指定部 +
1.の条件記述を満たすかどうか、つまり真か偽かをYかNで表します。\YはYesの頭文字であり、他にもT（True）と表現する場合もあります。NはNoの頭文字であり、他にもF（False）と表現する場合もあります。各条件記述のY/Nの組み合わせを指定するので、条件指定部と呼ばれます。 +

4.動作指定部 +
各列（これを"規則"と呼びます）で指定されている条件指定のY/Nの組み合わせによって決まる出力結果（動作）を示します。その条件の組み合わせによって動作する動作記述に「X」を指定します。バツではなくeXecution（実行）を意味します。「－」は逆に動作しないことを示します。動作を指定するので、動作指定部と呼びます。 +

## テスト定義、テスト開始、テスト終了メッセージのログ出力 +
サンプルコードにある +
    - test_doc定義のlog_msg出力 +
をサンプルコードと同様のタイミングで必ず出力処理を行ってください +

## python バージョン +
3.11.6以降を使用します、古い書き方は採用しません +

## 確認 +
前提・要件はOKでしょうか +
====

.prompt: step0
====
では<step0>から進めましょう

サンプルコード:

```python
import pytest
from pathlib import Path

####################################
# テスト対象モジュールimport
####################################
from src.lib.convertor_utils.ibr_excel_field_analyzer import RemarksParser

####################################
# テストサポートモジュールimport
####################################
# config共有
import sys
from src.lib.common_utils.ibr_enums import LogLevel
from src.lib.common_utils.ibr_decorator_config import initialize_config
config = initialize_config(sys.modules[__name__])
log_msg = config.log_message
log_msg(str(config), LogLevel.DEBUG)

class TestBusinessUnitCodeConverterInit:
    """BusinessUnitCodeConverterの__init__メソッドのテスト

    テスト構造:
    ├── C0: 基本機能テスト
    │   ├── 正常系: 有効な変換テーブルファイルでインスタンス生成
    │   ├── 異常系: 存在しないファイルでFileNotFoundError
    │   └── 異常系: 無効なファイル形式でException
    ├── C1: 分岐カバレッジ
    │   ├── 正常系: try文が正常に実行される
    │   ├── 異常系: FileNotFoundError分岐
    │   ├── 異常系: 無効なファイル形式でその他のException分岐
    │   └── 異常系: 権限エラーでその他のException分岐
    └── C2: 条件組み合わせ
        ├── 正常系: 有効なファイルでインスタンスが正常に生成される
        ├── 異常系: 存在しないファイルでFileNotFoundError
        ├── 異常系: 無効なpickleファイルでException
        ├── 異常系: 空のDataFrameを含むpickleファイルでException
        └── 異常系: 無効な構造のDataFrameを含むpickleファイルでException

    # C1のディシジョンテーブル
    | 条件                          | ケース1                | ケース2           | ケース3                    | ケース4                |
    |-------------------------------|------------------------|-------------------|----------------------------|------------------------|
    | ファイルが存在する            | Y                      | N                 | Y                          | Y                      |
    | ファイルが有効なpickle形式    | Y                      | -                 | N                          | Y                      |
    | ファイルに読み取り権限がある  | Y                      | -                 | -                          | N                      |
    | 出力                          | 正常にインスタンス生成 | FileNotFoundError | Exception (無効なファイル) | Exception (権限エラー) |

    境界値検証ケース一覧：
    | ケースID | 入力パラメータ | テスト値                             | 期待される結果  | テストの目的/検証ポイント                        | 実装状況 | 対応するテストケース |
    |----------|----------------|--------------------------------------|-----------------|--------------------------------------------------|----------|----------------------|
    | BVT_001  | file_name      | ""                                   | ValueError      | 空文字列の処理を確認                             | 実装済み | 具体的なテストメソッドを記載してください、他区分で実施済の場合は明示してください,以下同様に埋め込んでください |  
    | BVT_002  | file_name      | "人事_申請データ.xlsx"               | 1               | 正常系：人事データの処理を確認                   | 実装済み | |
    | BVT_003  | file_name      | "国企_申請データ.xlsx"               | 2               | 正常系：国企データの処理を確認                   | 実装済み | |
    | BVT_004  | file_name      | "関連(ダミー課あり)_申請データ.xlsx" | 3               | 正常系：関連（ダミー課あり）の処理を確認         | 実装済み | |
    | BVT_005  | file_name      | "関連(ダミー課なし)_申請データ.xlsx" | 4               | 正常系：関連（ダミー課なし）の処理を確認         | 実装済み | |
    | BVT_006  | file_name      | "invalid_申請データ.xlsx          "  | ValueError      | 無効なプレフィックスの処理を確認                 | 実装済み | |
    | BVT_007  | file_name      | "人事_申請データ"                    | ValueError      | 拡張子なしのファイル名の処理を確認               | 未実装   | |
    | BVT_008  | file_name      | "人事_申請データ.csv"                | ValueError      | 異なる拡張子のファイル名の処理を確認             | 未実装   | |
    | BVT_009  | file_name      | "人事_申請データ.XLSX"               | 1               | 大文字拡張子の処理を確認                         | 実装済み | |
    | BVT_010  | file_name      | "人事_申請データ_.xlsx"              | ValueError      | 不正なフォーマット（余分なアンダースコア）の確認 | 未実装   | |
    | BVT_011  | file_name      | "a" * 255 + "_申請データ.xlsx"       | ValueError      | 最大ファイル名長の処理を確認                     | 未実装   | |
    
    境界値検証ケースの実装状況サマリー：
    - 実装済み: 7
    - 未実装: 4
    - 一部実装: 0
    
    注記：
    . BVT_007, BVT_008, BVT_010, BVT_011 は現在未実装です。これらのケースは、ファイル名のバリデーションをより厳密に行うために追加するべきです。
    . 最大ファイル名長のテスト（BVT_011）は、実際の環境での制限に応じて調整が必要かもしれません。
    . 大文字/小文字の区別について、現在の実装では区別していないようですが、要件に応じて厳密にすべきかどうか検討が必要です。
    """
    def setup_method(self):
        # テスト定義をログ出力 このまま記述してください
        log_msg("test start", LogLevel.INFO)

    def teardown_method(self):
        log_msg(f"test end\n{'-'*80}\n", LogLevel.INFO)

    @pytest.fixture()
    def valid_conversion_table(self, tmp_path):
        """有効な変換テーブルのfixture"""
        file_path = tmp_path / "valid_table.pkl"
        df = pd.DataFrame({
            'business_unit_code_jinji': ['001', '002'],
            'main_business_unit_code_jinji': ['M001', 'M002'],
            'business_unit_code_bpr': ['B001', 'B002']
        })
        with file_path.open('wb') as f:
            pickle.dump(df, f)
        return file_path

    def test_init_C0_valid_file(self, valid_conversion_table):
        test_doc = """テスト内容:

        - テストカテゴリ: C0
        - テスト区分: 正常系
        - テストシナリオ: 有効な変換テーブルファイルでインスタンス生成
        """
        log_msg(f"\n{test_doc}", LogLevel.INFO)

        converter = BusinessUnitCodeConverter(valid_conversion_table)
        assert isinstance(converter.conversion_table, pd.DataFrame)
        assert not converter.conversion_table.empty


    def test_init_C0_file_not_found(self, tmp_path):
        test_doc = """テスト内容:

        - テストカテゴリ: C0
        - テスト区分: 異常系
        - テストシナリオ: 存在しないファイルでFileNotFoundError
        """
        log_msg(f"\n{test_doc}", LogLevel.INFO)

        non_existent_file = tmp_path / "non_existent.pkl"
        with pytest.raises(FileNotFoundError):
            BusinessUnitCodeConverter(non_existent_file)


    @pytest.mark.parametrize(("file_name", "expected"), [
        ("人事_申請データ.xlsx", 1),
        ("国企_申請データ.xlsx", 2),
        ("関連(ダミー課あり)_申請データ.xlsx", 3),
        ("関連(ダミー課なし)_申請データ.xlsx", 4),
    ])
    def test_generate_applicant_info_C0_valid_input(self, file_name, expected):
        test_doc = """テスト内容:
        - テストカテゴリ: C0
        - テスト区分: 正常系
        - テストシナリオ: 有効な入力でのテスト
        """
        log_msg(f"\n{test_doc}", LogLevel.INFO)

        result = generate_applicant_info(file_name)
        assert result == expected
        log_msg(f"Result: {result}", LogLevel.DEBUG)

    def test_generate_applicant_info_C2_case_and_bracket(self, file_name, expected):
        test_doc = """テスト内容:
        - テストカテゴリ: C2
        - テスト区分: 正常系
        - テストシナリオ: 大文字小文字と括弧の組み合わせテスト
        """
        log_msg(f"\n{test_doc}", LogLevel.INFO)

        applicant_types = {
            "人事": 1,
            "国企": 2,
            "関連(ダミー課あり)": 3,
            "関連(ダミー課なし)": 4,
        }

        if not any(key in file_name.lower() for key in applicant_types):
            with pytest.raises(ValueError) as exc_info:
                generate_applicant_info(file_name)
            error_message = str(exc_info.value)
            log_msg(f"ValueError raised: {error_message}", LogLevel.ERROR)
            assert "不正なファイル名パターン" in error_message
        else:
            result = generate_applicant_info(file_name)
            assert result == expected
            log_msg(f"Result: {result}", LogLevel.DEBUG)
    

    # 境界値テストのコードは別途実装サンプルを補填予定
    # テスト用関数は作成してください
```
====

.prompt:step1
====
それでは<Step1>に進みます

テスト対象モジュールの情報を提示します

## テスト対象モジュール配置場所 +
↓要件に応じて差し替えてください +
src.lib.converter_utils

## テスト対象モジュール名 +
↓要件に応じて差し替えてください +
ibr_mapping_layout_excel_to_integrated.py

## テスト対象モジュール +
↓テスト対象コードを貼り付けてください +
（ここにテストコードをベタッと貼り付け）

====

.prompt:step2〜step11
====
* step2から順次行い、モジュール全体分析と壁打ちを行ってください（ここ、重要）
====

.prompt:step12〜step20
====
* メソッド毎に分析、テストコードを評価します 
* 原則全てのメソッドに適用します,メソッドの数だけ、step12〜step20を繰り返します
====

---

.prompt:最終step
====
* テスト全体に対するチェックリスト評価を実施します 
====

====
生成されたテストコード全体を以下に貼り付けてください。この全体コードに対して最終品質チェックを行います。

!!ここに生成されたテストコード全体を貼り付け/再表示!!

<最終step>

    * 生成されたテストコード全体に対する品質チェックリストの適用と結果の提示を行います。
    * 以下の品質チェックリストを使用して、生成されたテストコード全体を評価し、結果を提示します。
    * この結果は、人間のレビュアーが最終判断と改善決定を行うための参考情報となります。

    評価結果をテーブル形式で以下のように出力してください：
    テーブルの縦棒位置は揃えてください

    | 項目番号  | 項目名           | 評価    | 評価コメント   |
    |-----------|------------------|---------|----------------|
    | 1         | テストの独立性   | [評価]  | [評価コメント] |
    | 2         | テストの網羅性   | [評価]  | [評価コメント] |
    ...

    [評価] には "pass", "fail", "partial pass" のいずれかを入力してください。
    [評価コメント] には簡潔な評価の理由や観察を記入してください。

    1. テストの独立性
        - 各テストが他のテストに依存していないか
        - テストの実行順序が結果に影響しないか

    2. テストの網羅性
        - 全てのパブリックメソッドがテストされているか
        - 正常系と異常系の両方がテストされているか

    3. 境界値テストの適切性
        - 各入力パラメータに対して適切な境界値テストが実施されているか
        - 最小値、最大値、およびその前後の値がテストされているか
        - 特殊な入力（null、空文字列など）に対するテストが含まれているか

    4. 境界値テストの網羅性
        - 境界値設定一覧に記載された全てのケースがテストされているか
        - 未実装のケースが適切に文書化され、その理由が説明されているか

    5. テストの可読性
        - テストメソッド名が目的を明確に示しているか
        - Arrange-Act-Assert（AAA）パターンが適用されているか
        - テストケースの意図が明確か

    6. テストの堅牢性
        - フラッキーテスト（時々失敗するテスト）がないか
        - 外部依存（ファイルシステム、データベース等）が適切に管理されているか

    7. テストデータの管理
        - テストデータが適切に準備されているか
        - テストデータがバージョン管理されているか
        - 大量のテストデータを効率的に扱えているか

    8. モックとスタブの適切な使用
        - 外部依存が適切にモック化されているか
        - モックの使用が過剰でないか

    9. アサーションの品質
        - アサーションが具体的で明確か
        - 複数の状態を確認する場合、個別のアサーションが使用されているか

    10. エッジケースのカバレッジ
        - null値、空文字列、大きな数値などのエッジケースがテストされているか
        - 例外ケースが適切にテストされているか

    11. パフォーマンスとリソース管理
        - テストの実行時間が適切か
        - リソース（メモリ、ファイルハンドルなど）が適切に解放されているか

    12. テストの隔離
        - テストがグローバル状態を変更していないか
        - テスト後の適切なクリーンアップが行われているか

    13. パラメータ化テスト
        - 類似のテストケースが適切にパラメータ化されているか
        - データプロバイダが効果的に使用されているか

    14. コードカバレッジ
        - 行カバレッジ、分岐カバレッジ、条件カバレッジが十分か
        - 未テストのコードパスが明確に識別されているか

    15. テストの保守性
        - テストコードに重複がないか
        - テストヘルパー関数が適切に使用されているか

    16. テストの粒度
        - 各テストが単一の概念や機能をテストしているか
        - テストが適切なサイズと複雑さを保っているか

    17. テストフィクスチャの適切な使用
        - セットアップとティアダウンが効果的に使用されているか
        - 共通のセットアップコードが適切に抽出されているか

    18. 例外処理のテスト
        - 予期される例外が適切にテストされているか
        - 例外メッセージや型が検証されているか

    19. 非決定的な要素の処理
        - 日付、乱数などの非決定的な要素が適切に制御されているか

    20. ドキュメンテーション
        - 複雑なテストケースに対して適切なコメントが付与されているか
        - テストの目的や前提条件が明確に記述されているか
        - 境界値テストケースが適切に文書化されているか

    21. テストの一貫性
        - プロジェクト全体で一貫したテストスタイルが維持されているか

    22. 負のテスト
        - システムが適切にエラーを処理することを確認するテストが含まれているか

    23. 境界値テストの一覧性
        - 境界値テストケースが一覧化され、テストクラスのdocstringに含まれているか
        - 境界値テストの実装状況が明確に記録されているか

    評価結果の要約:
    - 全体的な品質評価:
    - 主要な強み:
    - 潜在的な改善領域:
    - 追加の考察:

</最終step>
====

[IMPORTANT]
====
* この評価結果は自動生成されたものであり、参考情報として提供されています。
* 最終的な品質判断、改善の必要性、および具体的な修正方法の決定は、人によるレビュー責任で行ってください。
====

== 推奨される次のステップ:
. 人によるレビューで詳細な確認
. プロジェクト固有の要件や基準に基づく評価
. 必要に応じたテストコードの手動修正
. レビュー結果に基づく、テストコード生成プロセスの改善検討
. 境界値テストケースの網羅性と実装状況の再確認
