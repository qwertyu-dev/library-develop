=== システムの特性と主要フロー

=== システムの全体像

本システムは、人事異動に関わる部署情報を管理するシステムです。その中核となる特徴は、業務ロジックをExcelで定義し、それを実行時に利用する仕組みにあります。このExcelで定義された業務ロジックは「Facade定義」と呼ばれ、システムの処理パターンを制御する重要な役割を担っています。

システムの実行においては、このFacade定義をExcel形式からpickle形式に変換して利用します。この変換はビルド時に自動的に行われ、実行時のパフォーマンスを最適化しています。pickle形式への変換により、データの読み込み速度が向上し、大量のデータを効率的に処理することが可能となっています。

=== リリースフロー全体像

[plantuml]
....
@startuml
title リリースフロー全体概要

swimlane 開発フェーズ
|ソース管理|
start
:feature開発;
:リリースブランチへfeatureから資源マージ;
:Tag付与;

|データ準備|
:申請データ登録;
:部店カナ付与;
:承認済データ配置;

|Jenkins実行|
:テスト実行トリガー;
:リリースブランチ取得;
:Facade定義変換;
:ビルド実行;

|リグレ環境|
:デプロイ実行;
:データ配置;
:一括申請処理実行;
if (実行結果判定) then (OK)
  :更新リクエスト生成;
else (NG)
  :エラー対応;
  stop
endif

|リリース判断|
:処理結果/生成データ確認;
if (判定) then (OK)
  :リリース承認;
else (NG)
  :差し戻し;
  stop
endif

|最終化|
:masterマージ;
:本番Tag付与;
:データ移行実行;
stop
@enduml
....


==== システムの基本特性

本システムは、人事異動に関わる部署情報を管理するシステムです。その中核となる特徴は、業務ロジックをExcelで定義し、それを実行時に利用する仕組みにあります。このExcelで定義された業務ロジックは「Facade定義」と呼ばれ、システムの処理パターンを制御する重要な役割を担っています。

システムの実行においては、このFacade定義をExcel形式からpickle形式に変換して利用します。この変換はビルド時に自動的に行われ、実行時のパフォーマンスを最適化しています。pickle形式への変換により、データの読み込み速度が向上し、大量のデータを効率的に処理することが可能となっています。

また、本システムではプログラムとデータを明確に分離して管理しています。プログラム資源はソースコードとビルドされたパッケージとして管理され、データ資源はリファレンスファイルと更新リクエストファイルとして管理されます。この分離により、データの更新とプログラムの更新を独立して行うことが可能となり、システムの保守性と柔軟性を高めています。

[plantuml]
....
@startuml
title システムの基本構成

package "システム構成要素" {
    folder "プログラム資源" {
        [ソースコード] as src
        [Facade定義\n(Excel)] as facadeXlsx
    }
    
    folder "実行環境" {
        [ビルドパッケージ] as pkg
        [Facade定義\n(pickle)] as facadePickle
    }
    
    folder "データ資源" {
        [リファレンス] as ref
        [更新リクエスト] as req
    }
}

facadeXlsx --> facadePickle : 変換
src --> pkg : ビルド
@enduml
....

==== Facade定義の変換処理

本システムにおける業務ロジックは、Excelファイルの形で管理されています。このExcelファイルには、データ処理のパターンや条件判定のロジック、さらには具体的な編集規則が定義されています。開発者はこのExcelファイルを編集することで、業務ロジックの追加や変更を容易に行うことができます。

実際の運用においては、このExcel形式のFacade定義をそのまま使用することはできません。そのため、ビルドプロセスの一環として、これらのExcelファイルをpickle形式に変換する処理を行います。この変換処理は自動化されており、開発者が意識する必要はありません。変換されたpickleファイルは、実行環境のdef配下に配置され、システムの実行時に利用されます。

[plantuml]
....
@startuml
title Facade定義の変換フロー

|開発環境|
partition "doc領域" {
    :Facade定義.xlsx;
}

|ビルドプロセス|
:Excel読み込み;
:データ構造変換;
:pickle形式生成;

|実行環境|
partition "def領域" {
    :Facade定義.pickle;
}

@enduml
....

==== 実行環境用データの準備

システムの実行には、最新の部署情報を含むリファレンスファイルと、これまでの変更履歴を含む更新リクエストファイルが必要です。これらのファイルは本番環境から取得し、リグレッション環境で利用します。

リファレンスファイルは、現時点での部署情報のマスターデータとして機能します。このファイルには、部署コードや名称、階層構造などの基本情報が格納されています。一方、更新リクエストファイルには、部署情報の変更履歴が記録されています。これらのファイルはいずれもpickle形式で管理されており、システムで効率的に処理できる形式となっています。

これらのデータファイルは、本番環境から定期的に取得し、データリポジトリに保存されます。保存時にはバージョン管理のためのタグが付与され、必要に応じて過去の状態に戻すことも可能です。リグレッション環境では、これらの最新データを用いて検証を行います。

==== リグレッション環境の構築

リグレッション環境の構築は、実際の業務処理の検証を行うための重要なステップです。この環境構築には、ビルドされたプログラムパッケージと、本番から取得したデータファイルの両方が必要となります。

ビルドパッケージには、pickle形式に変換されたFacade定義、コンパイル済みのプログラム、各種設定ファイルが含まれています。これらのファイルは、Jenkinsを使用して自動的にリグレッション環境に配置されます。配置後は、環境設定の適用や基本的な動作確認が行われ、業務処理の準備が整います。

==== 一括申請データの処理

実際の業務処理は、人事部などから送付される一括申請データを使用して行われます。この申請データはExcel形式で提供され、事前のチェックや部店カナの付与などの準備作業を経て処理されます。

リグレッション環境では、この申請データを用いて一連の処理を実行します。処理の過程では、Facade定義に基づいて様々なパターンの処理が実行され、その結果として新たな更新リクエストファイルが生成されます。生成された更新リクエストファイルは、内容の検証を経て、最終的に本番環境への反映が検討されます。

このように、システム全体としては、開発資源の準備から始まり、ビルド処理、環境構築、そして実際の業務処理までが一連のフローとして実行されます。各フェーズでの処理は自動化されており、人手による作業は最小限に抑えられています。


=== リポジトリ管理

=== ソースリポジトリ管理

本システムのソースリポジトリは、開発からリリースまでの過程を管理し、システムの品質を担保するための重要な基盤となっています。以下では、ソースリポジトリの管理方針と運用方法について説明します。

==== ブランチ戦略

本システムでは、効率的な開発とリリース管理を実現するため、主に3つのブランチを使用します。まず、masterブランチは本番環境で稼働中のソースコードを管理する基幹ブランチとして位置づけられています。この安定したコードベースを起点として、新機能開発やバグ修正のためのfeatureブランチが作成されます。

featureブランチでの開発が完了すると、その変更はリリースブランチへと統合されます。リリースブランチは、本番環境への反映を前提とした検証を行うための重要な場所となります。ここでの検証が完了し、承認された変更のみがmasterブランチへと反映される流れとなります。

[plantuml]
....
@startuml
title ブランチ管理の基本フロー

skinparam noteBackgroundColor lightGrey
skinparam noteBorderColor Black

|master|
start
fork
  |feature|
  :機能開発;
  :単体テスト;
  |release|
  :変更統合;
  :検証実施;
  if (検証結果) then (OK)
    |master|
    :変更反映;
  else (NG)
    |feature|
    :修正対応;
  endif
end fork
stop
@enduml
....

==== Tag管理

リリースブランチでの検証過程では、各段階でTagを付与することで、システムの状態を明確に管理します。Tagの付与は検証フェーズの進行に応じて行われ、リグレッション環境での検証用Tag（R1.0.0_REG_YYYYMMDD）から、本番リリース用Tag（R1.0.0_PROD_YYYYMMDD）まで、システムの状態を時系列で追跡可能とします。

各Tagは、そのリリースにおけるシステムの完全な状態を示すスナップショットとして機能します。これにより、問題発生時の状態復元や、過去バージョンとの比較が容易になります。また、本番リリース時のTagは、そのバージョンが本番環境で正常に稼働していることを示す証跡としても活用されます。

=== データリポジトリ管理

==== リポジトリ構成

データリポジトリは、システムで使用される各種データファイルを管理します。特に重要な要素として、以下のデータ群を管理します。

まず、currentディレクトリには現在処理中のアクティブなデータが格納されます。これには申請データ、リファレンスファイル、更新リクエストファイルが含まれます。特に申請データについては、その処理状態に応じて、pendingディレクトリ（処理待ち）、kana-addedディレクトリ（部店カナ付与済）、approvedディレクトリ（承認済）と、状態遷移に応じた管理が行われます。

一方、historyディレクトリには、過去に処理が完了したデータが履歴として保管されます。これらのデータは、システムの処理履歴を追跡する際の重要な情報源となります。特に、リファレンスファイルと更新リクエストファイルの履歴は、部署情報の変更履歴を把握する上で重要な役割を果たします。

[plantuml]
....
@startuml
title データリポジトリ構成

package "data-repository" {
    folder "current" {
        folder "applications-current" as app_current {
            [pending]
            [kana-added]
            [approved]
        }
        [reference-current] as ref_current
        [requests-current] as req_current
    }
    
    folder "history" {
        [applications-history] as app_history
        [reference-history] as ref_history
        [requests-history] as req_history
    }
}

note right of history
  全履歴を保持
  Tag管理により
  時点を特定可能
end note
@enduml
....

==== データライフサイクル管理

データリポジトリでのデータ管理は、厳密なライフサイクル管理の下で行われます。一括申請データは、メールで受領した時点でpendingディレクトリに格納され、処理の進行に応じて適切なディレクトリに移動されていきます。

特に重要なのが、master反映のタイミングでのデータ移行プロセスです。このタイミングで、currentディレクトリ内の処理済みデータはhistoryディレクトリに移行され、履歴として永続的に保管されます。この移行は、JenkinsのJOBとして自動化されており、データの整合性チェックを含めた安全な移行が実現されています。

[plantuml]
....
@startuml
title データライフサイクル管理

|受付|
start
:メール受領;
:pendingへ格納;

|処理|
:カナ付与;
:kana-addedへ移動;
:承認取得;
:approvedへ移動;

|履歴化|
:master反映;
:historyへ移行;
:Tag付与;
stop

note right
  移行はJenkinsで自動実行
  データ整合性を確認
end note
@enduml
....

=== 自動化プロセス

=== テスト実行

==== 自動テスト環境

本システムの品質担保において、自動テストの実行は重要な役割を果たします。テスト実行は、リリースブランチに対して実施され、Jenkinsによって自動化されています。自動テストは、単体テスト（UT）と結合テスト（IT）の両方を含み、システムの機能的な正常性を確認します。

テスト環境では、リリースブランチから取得したソースコードと、テスト用のデータセットを使用します。特に重要なのは、pickle形式に変換されたFacade定義を使用した処理の検証です。これにより、実際の運用環境と同様の条件下でのテストが可能となります。

[plantuml]
....
@startuml
title テスト実行環境構成

package "テスト環境" {
    folder "プログラム" {
        [ビルド済パッケージ] as build
        [Facade定義(pickle)] as facade
    }
    
    folder "テストデータ" {
        [リファレンス] as ref
        [更新リクエスト] as req
        [一括申請データ] as app
    }
    
    folder "テストコード" {
        [単体テスト] as ut
        [結合テスト] as it
    }
}

build --> ut : 検証対象
facade --> ut : 検証対象
ref --> it : テストデータ
req --> it : テストデータ
app --> it : テストデータ

note right of it
  全てのテストが
  Cleanであること
  が必須
end note
@enduml
....

==== テスト実行プロセス

テスト実行は、手動でJenkinsジョブをトリガーすることから始まります。このジョブは、指定されたTagのリリースブランチを取得し、以下の一連のプロセスを実行します。まず、Facade定義のExcelファイルをpickle形式に変換し、その後プログラムのビルドを行います。これにより、テスト実行に必要な環境が準備されます。

プログラムのビルドが完了すると、自動テストが実行されます。単体テストでは、各モジュールの機能が正しく動作することを確認します。結合テストでは、実際の業務フローに沿ったデータ処理を行い、システム全体としての整合性を検証します。これらのテストは全て自動的に実行され、その結果はJenkinsのログとして保存されます。

[plantuml]
....
@startuml
@startuml
title テスト実行フロー

|Jenkins|
start
:Tagの取得;
:Facade定義変換;
:ビルド実行;

|テスト実行|
:単体テスト;
note right: UT全件Clean必須
if (結果) then (NG)
  stop
else (OK)
  :結合テスト;
  note right: IT全件Clean必須
  if (結果) then (NG)
    stop
  endif
endif

|結果確認|
:テスト結果確認;
note right: 5世代分のログを保持
:ログ保存;
stop
@enduml
....

=== データ移行

==== 移行プロセス

データ移行プロセスは、masterブランチへの反映が承認された後、自動的に実行されます。このプロセスでは、currentディレクトリに格納された処理済みのデータをhistoryディレクトリに移行します。この移行は、データの一貫性と完全性を保証するため、厳密な手順に従って実行されます。

移行対象となるデータには、承認済みの一括申請データ、リファレンスファイル、更新リクエストファイルが含まれます。これらのデータは、移行前に整合性チェックが行われ、全てのファイルが正しく移行されることを確認します。移行完了後は、新たなTagが付与され、移行が正常に完了したことが記録されます。

[plantuml]
....
@startuml
title データ移行フロー

|移行準備|
start
:master反映承認;
:移行対象特定;

|整合性チェック|
:ファイル数確認;
note right: 移行前後での\nファイル数一致確認
:サイズ確認;
note right: データサイズの\n整合性チェック
if (チェック結果) then (NG)
  :エラー通知;
  stop
endif

|移行実行|
:current→history移行;
:移行結果確認;
:Tag付与;
note right: 移行完了を\nTagで記録

|完了処理|
:current更新;
:ログ保存;
note right: 5世代分保持
stop
@enduml
....

==== 移行後の検証

データ移行完了後は、移行結果の検証が行われます。この検証では、移行前後でのファイル数の一致、データサイズの整合性、さらにファイルの内容が正しく移行されていることを確認します。検証結果はJenkinsのログとして保存され、5世代分が保持されます。

検証が成功すると、currentディレクトリの処理済みデータがクリアされ、新たな処理の準備が整います。この一連の流れにより、データの履歴管理と新規データの処理が、安全かつ確実に実行されることが保証されます。


=== 運用ルール

=== 実行時確認事項

==== 事前確認

リリース作業を開始する前に、必要な準備と確認を実施します。この段階での確認は、後続の作業を円滑に進めるために重要です。

まず、開発完了したfeatureブランチの内容について、開発担当者とレビューアによる最終確認を行います。ここでは、実装内容が要件を満たしていること、コーディング規約に準拠していること、さらに単体テストが正常に完了していることを確認します。

次に、リリースブランチへの統合準備として、以下の点を確認します。複数のfeatureブランチを同時に統合する場合は、それらの間の依存関係や影響範囲を特に注意深く確認します。また、Facade定義の変更がある場合は、その内容と影響範囲について、業務部門との最終確認を実施します。

[plantuml]
....
@startuml
title 事前確認フロー

|開発担当者|
start
:feature開発完了;
:単体テスト実施;
:実装内容確認;

|レビューア|
:コード内容確認;
:テスト結果確認;
if (確認結果) then (NG)
  :差し戻し;
  stop
endif

|統合担当者|
:依存関係確認;
:影響範囲確認;
if (Facade定義変更有) then (yes)
  :業務部門確認;
endif

|承認者|
:最終確認;
:統合承認;
stop
@enduml
....

==== 実行時確認

システムの実行時には、各フェーズでの確認ポイントが定められています。これらの確認は、システムの正常性を担保するために重要です。

Jenkinsでのビルド実行時には、まずFacade定義の変換が正しく完了することを確認します。変換されたpickleファイルのサイズや内容が想定通りであることを確認することで、後続の処理での問題を防ぎます。

テスト実行時には、単体テストと結合テストの両方が全件Cleanとなることを確認します。一件でもエラーが発生した場合は、即座に原因の調査と対応を行います。テスト結果は詳細に確認し、想定通りの動作となっていることを確認します。

[plantuml]
....
@startuml
title 実行時確認フロー

|Jenkins実行|
start
:ビルド開始;
:Facade定義変換;
note right: 変換結果の確認
:テスト実行;

|テスト確認|
if (単体テスト) then (NG)
  :エラー調査;
  stop
else (OK)
  :結合テスト;
  if (結果) then (NG)
    :エラー調査;
    stop
  endif
endif

|結果確認|
:テストログ確認;
:カバレッジ確認;
:実行結果判定;
stop
@enduml
....

==== 事後確認

実行完了後は、結果の確認と記録を行います。これは、システムの品質管理と、将来の改善のために重要な工程です。

まず、全ての処理が正常に完了したことを確認します。特に、データの移行が正しく行われたことを、ファイル数とサイズの両面から確認します。また、生成された更新リクエストの内容が、業務的に正しいものであることを確認します。

全ての確認が完了した後、実行結果のログを保存します。ログには実行時の状況だけでなく、確認時に気付いた点や、将来の改善点なども記録します。これらの情報は、システムの継続的な改善に活用されます。

[plantuml]
....
@startuml
title 事後確認フロー

|実行結果確認|
start
:処理完了確認;
:データ移行確認;
note right: ファイル数/サイズ確認

|業務確認|
:更新リクエスト確認;
if (確認結果) then (NG)
  :原因調査;
  stop
endif

|記録|
:結果ログ保存;
note right: 5世代分保持
:気付き点記録;
:改善点記録;
stop
@enduml
....


=== システム定義

=== リポジトリ構成

==== ソースリポジトリの詳細構造

ソースリポジトリは、システムの開発資源とビルド用の設定を管理する重要な基盤です。その構造は、システムの保守性と拡張性を考慮して設計されています。

[plantuml]
....
@startuml
title ソースリポジトリ構造

package "repository-root" {
    folder "src" {
        [application] as app
        [batch] as batch
        [common] as common
    }

    folder "doc" {
        [Facade定義.xlsx] as facade
        [パターン定義.xlsx] as pattern
    }

    folder "def" {
        [Facade定義.pickle] as facade_pickle
        [パターン定義.pickle] as pattern_pickle
    }

    folder "test" {
        [unit-test] as ut
        [integration-test] as it
    }
}

facade --> facade_pickle : ビルド時変換
pattern --> pattern_pickle : ビルド時変換

note right of doc
  開発時の定義資源
end note

note right of def
  実行時の定義資源
end note
@enduml
....

src配下には、システムの主要なプログラムコードが配置されます。applicationには画面やAPIなどのエンドポイント処理、batchにはバッチ処理、commonには共通機能が格納されます。この構造により、機能単位での開発と保守が容易になります。

doc配下には、システムの動作を制御するFacade定義やパターン定義のExcelファイルが配置されます。これらのファイルは開発時に編集され、ビルド時にdef配下のpickleファイルに変換されます。変換されたpickleファイルは、システムの実行時に使用されます。

==== データリポジトリの詳細構造

データリポジトリは、システムで使用される各種データファイルを管理します。その構造は、データのライフサイクルと状態遷移を考慮して設計されています。

[plantuml]
....
@startuml
title データリポジトリ構造

package "data-repository" {
    folder "current" as current {
        folder "applications" as app_current {
            [pending] as pending
            [kana-added] as kana
            [approved] as approved
        }
        [reference-current] as ref_current
        [requests-current] as req_current
    }
    
    folder "history" as history {
        [applications-history] as app_history
        [reference-history] as ref_history
        [requests-history] as req_history
    }
}

pending --> kana : カナ付与後
kana --> approved : 承認後
approved --> app_history : 処理完了後
ref_current --> ref_history : 更新時
req_current --> req_history : 更新時

note right of current
  処理中データ
end note

note right of history
  永続保管データ
end note
@enduml
....

=== Jenkinsジョブ構成

==== ジョブ一覧

Jenkinsでは、システムのビルドからテスト実行、データ移行までの一連の処理を自動化するジョブが定義されています。各ジョブは固有の役割を持ち、システムの品質を担保します。

[plantuml]
....
@startuml
title Jenkinsジョブ構成

package "Jenkins" {
    folder "ビルドジョブ群" {
        [Facade変換] as convert
        [プログラムビルド] as build
        [テスト実行] as test
    }
    
    folder "データ管理ジョブ群" {
        [データ移行] as migrate
        [整合性チェック] as check
        [履歴管理] as history
    }
}

convert --> build
build --> test
test --> migrate : 成功時のみ
migrate --> check
check --> history : 成功時のみ

note right of test
  全件Clean必須
end note

note right of check
  ファイル数
  サイズ一致確認
end note
@enduml
....

各ジョブは以下の順序で実行されます：

まず、Facade変換ジョブがExcel形式の定義ファイルをpickle形式に変換します。この変換が成功すると、プログラムビルドジョブが実行され、システムの実行モジュールが作成されます。

ビルド完了後、テスト実行ジョブが起動し、単体テストと結合テストを実行します。全てのテストがCleanとなった場合のみ、後続のデータ移行ジョブが実行されます。

データ移行ジョブでは、current配下のデータをhistory配下に移行します。移行後は整合性チェックジョブが実行され、データの完全性が確認されます。最後に履歴管理ジョブが実行され、移行完了を示すTagが付与されます。

この一連のジョブは、手動でトリガーされ、各ジョブの実行結果は5世代分が保持されます。エラーが発生した場合は、そのジョブの時点で処理が停止し、エラーの内容が通知されます。


=== 異常時対応

=== エラー検知

==== エラーの種類と特徴

システムの運用において発生する可能性のあるエラーは、大きく以下の三つのカテゴリに分類されます。それぞれのエラーに対して、適切な検知方法と対応手順が定められています。

まず、ビルド・テスト実行時のエラーです。これには、Facade定義の変換エラー、プログラムのビルドエラー、テスト実行時のエラーが含まれます。これらのエラーは、Jenkinsのジョブ実行ログに詳細が記録され、即座に検知することができます。

次に、データ処理時のエラーです。一括申請データの処理や、データ移行時に発生する可能性があります。これらのエラーは、処理ログやデータの整合性チェックによって検知されます。データの不整合や、予期せぬ状態変化などが、このカテゴリのエラーとして捉えられます。

最後に、環境に起因するエラーです。リソース不足やネットワーク障害など、システムの実行環境に関連するエラーがこれに該当します。これらのエラーは、システムログやリソースモニタリングによって検知されます。

[plantuml]
....
@startuml
title エラー検知フロー

|ビルド・テスト|
partition "ビルド関連" {
    :Facade変換エラー;
    note right: Excel→pickle変換失敗
    :ビルドエラー;
    note right: コンパイルエラー
    :テストエラー;
    note right: テスト失敗
}

|データ処理|
partition "データ関連" {
    :処理エラー;
    note right: 一括申請処理失敗
    :整合性エラー;
    note right: データ不整合検出
    :移行エラー;
    note right: データ移行失敗
}

|環境障害|
partition "環境関連" {
    :リソースエラー;
    note right: メモリ/ディスク不足
    :ネットワークエラー;
    note right: 通信障害
}
@enduml
....

=== エラー発生時の対応手順

エラーが検知された場合、以下の手順に従って対応を行います。これらの手順は、エラーの影響を最小限に抑え、迅速な復旧を実現するために設計されています。

まず、エラーの内容を正確に把握します。エラーメッセージ、発生時の状況、影響範囲などの情報を収集します。これらの情報は、後続の対応や、再発防止策の検討に重要な役割を果たします。

次に、エラーの影響範囲を特定します。データの整合性への影響、他の処理への波及効果、システム全体への影響などを評価します。この評価結果に基づいて、必要な対応レベルを判断します。

[plantuml]
....
@startuml
title エラー対応フロー

|一次対応|
start
:エラー検知;
:状況確認;
:ログ収集;

|影響調査|
:範囲特定;
:重要度判定;
if (緊急度) then (高)
    :行内規約に基づく\nエスカレーション;
else (低)
    :通常対応;
endif

|対策実施|
:原因分析;
:対策検討;
:修正実施;

|確認|
:動作確認;
:再発防止策検討;
stop
@enduml
....

=== リカバリ手順

エラーからの復旧には、以下の手順でリカバリを実施します。これらの手順は、システムを安全かつ確実に正常状態に戻すために設計されています。

まず、エラーが発生した時点の状態を保全します。処理中のデータやログを保存し、後の分析に備えます。特に、データの整合性に関わるエラーの場合、現状のデータを確実にバックアップします。

次に、エラーの原因に応じた復旧手順を実行します。ビルドエラーの場合は修正とリビルド、データエラーの場合は正常なデータの再ロード、環境エラーの場合はリソースの再確保などを行います。

[plantuml]
....
@startuml
title リカバリフロー

|状態保全|
start
:現状保存;
:ログバックアップ;

|復旧判断|
if (エラー種別) then (ビルド系)
    :修正・リビルド;
else if (データ系) then
    :データ再ロード;
else (環境系)
    :環境再構築;
endif

|確認|
:動作検証;
if (結果) then (OK)
    :完了報告;
else (NG)
    :原因再調査;
endif
stop
@enduml
....

特に重要なのは、リカバリ完了後の検証です。エラーが確実に解消されていること、システムが正常に動作していること、データの整合性が保たれていることを、慎重に確認します。また、同様のエラーの再発を防ぐための対策を検討し、必要に応じてシステムや運用手順の改善を行います。