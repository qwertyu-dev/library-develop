= リファレンステーブルデータのキャッシュ戦略設計書

== はじめに

=== 目的
本文書は、リファレンステーブルデータに対するキャッシュ戦略を定義し、効率的なデータアクセスを実現することを目的とする。

=== 背景
ディシジョンテーブル内のチェック処理において、リファレンステーブルデータへの頻繁なアクセスが発生している。パフォーマンス向上のため、適切なキャッシュ戦略の導入が必要とされている。

=== スコープ
本設計書は、リファレンステーブルデータのキャッシュ戦略の設計、実装方針、および性能評価を対象とする。

== システム概要

=== リファレンステーブルデータの特性
* データ形式: pickle
* レコード数: 約10,000件
* 主な用途: ディシジョンテーブル内のチェック処理での参照

=== ディシジョンテーブルとの関係
* ディシジョンテーブル内のチェック部品が、リファレンステーブルデータを参照して各種判定を行う

=== 性能要件
* データロード時間: 1秒以内
* メモリ使用量: 最大500MB以内

== キャッシュ戦略

===  キャッシュの必要性
頻繁なデータアクセスによるI/O負荷の軽減と、処理速度の向上のためにキャッシュの導入が必要。

=== キャッシュ対象データ
リファレンステーブルデータ全体をキャッシュ対象とする。

=== キャッシュ更新ポリシー
* ファイル更新検知: ファイルの最終更新日時を確認
* 更新間隔: 最小1分間隔でファイル更新を確認
* キャッシュクリア: ファイル更新検知時に自動的にキャッシュをクリア

== キャッシュ実装オプション

=== functools.lru_cache

.主要パラメータ
[options='header', cols='1, 3, 3']
|===
| パラメータ | 説明 | 推奨値 
| maxsize    | キャッシュするアイテムの最大数 | None（無制限）または 1 
| typed      | 引数の型の違いを区別するかどうか | False 
|===

==== 利用推奨設定
[source, python]
----
@lru_cache(maxsize=1)
def load_data(file_path):
    # データロード処理
----

==== ファイル更新検出の考察
* lru_cacheにはファイル更新する機能が標準実装されていない。そのため自前でファイル検出処理ラッパーを実装する必要がある。

=== joblib

.主要パラメータ
[options='header', cols='1, 3, 3']
|===
| パラメータ | 説明 | 推奨値 
| cachedir   | キャッシュファイルを保存するディレクトリ | './joblib_cache' 
| verbose    | 詳細なログ出力レベル | 0 
| compress   | キャッシュデータの圧縮レベル | 3 
| mmap_mode  | メモリマッピングモード | 'r' 
|===

==== 利用推奨設定
[source, python]
----
from joblib import Memory
memory = Memory(cachedir='./joblib_cache', verbose=0)

@memory.cache
def load_data(file_path):
    # データロード処理
----

=== diskcache

==== 主要パラメータ
[options='header', cols='1, 3, 3']
|===
| パラメータ | 説明 | 推奨値 
| directory  | キャッシュファイルを保存するディレクトリ | './diskcache_cache' 
| size_limit | キャッシュの最大サイズ（バイト） | None（無制限）または 1GB 
| eviction_policy | キャッシュ削除ポリシー | 'least-recently-used' 
|===

==== 利用推奨設定
[source, python]
----
from diskcache import Cache
cache = Cache('./diskcache_cache')

def load_data(file_path):
    key = f'data:{file_path}'
    data = cache.get(key)
    if data is None:
        # データロード処理
        cache.set(key, data)
    return data
----

=== cachetools
==== 主要パラメータ
[options='header', cols='1, 3, 3']
|===
| パラメータ | 説明 | 推奨値 
| mazsizse  | キャッシュするアイテムの最大数 | 1 
| ttl | キャッシュエントリの有効期間 秒 | 3600s 
|===

==== 利用推奨設定
[source, python]
----
from cachetools import TTLCache, cached

def get_file_mtime(file_path):
    return os.path.getmtime(file_path)

ttl_cache = TTLCache(maxsize=1, ttl=3600)

@cached(cache=ttl_cache, key=lambda file_path: (file_path, get_file_mtime(file_path)))
def load_data(file_path):
    # データロード処理
----

==== ファイル更新検出の考察
cachetoolsにはファイル更新を検出してリロードする仕組みを標準実装していない。そのためパラメータにファイルタイムスタンプを渡すことでファイル更新時にはデータをロードする制御を行う。手段としては確立されている。

== 性能比較

=== テスト環境
- パプリカ

=== テストデータ生成/検証コード
[source, python]
----
import pandas as pd
import numpy as np
import time
import os
import psutil
import gc
from functools import lru_cache
from joblib import Memory
from diskcache import Cache
from cachetools import TTLCache, cached

# テストデータの生成
def generate_large_test_data(n_rows=1000000, n_cols=50):
    np.random.seed(42)
    data = {
        'id': np.random.randint(0, 1000, n_rows),
        'timestamp': pd.date_range(start='2023-01-01', periods=n_rows, freq='S')
    }
    
    for i in range(2, n_cols):
        data[f'value_{i}'] = np.random.rand(n_rows)
    
    df = pd.DataFrame(data)
    df.to_pickle('test_data_large.pkl')
    print(f"Generated test data: {n_rows} rows, {n_cols} columns")

# キャッシュ実装
@lru_cache(maxsize=1)
def load_data_lru_cache(file_path):
    return pd.read_pickle(file_path)

joblib_memory = Memory('./joblib_cache', verbose=0)
@joblib_memory.cache
def load_data_joblib(file_path):
    return pd.read_pickle(file_path)

diskcache = Cache('./diskcache_cache')
def load_data_diskcache(file_path):
    key = f'data:{file_path}'
    data = diskcache.get(key)
    if data is None:
        data = pd.read_pickle(file_path)
        diskcache.set(key, data)
    return data

def load_data_no_cache(file_path):
    return pd.read_pickle(file_path)

# cachetoolsの改善された実装
def get_file_mtime(file_path):
    return os.path.getmtime(file_path)

ttl_cache = TTLCache(maxsize=1, ttl=3600)  # 1時間のTTL

@cached(cache=ttl_cache, key=lambda file_path: (file_path, get_file_mtime(file_path)))
def load_data_cachetools(file_path):
    return pd.read_pickle(file_path)

# 複雑な操作の例
def perform_operation(df):
    result = df.groupby('id').agg({
        'value_2': 'mean',
        'value_3': 'sum',
        'value_4': 'max',
        'value_5': 'min'
    })
    return result

# パフォーマンス測定関数
def measure_performance(load_func, file_path, num_iterations=100):
    gc.collect()
    process = psutil.Process(os.getpid())
    start_mem = process.memory_info().rss

    start_time = time.time()
    for _ in range(num_iterations):
        df = load_func(file_path)
        result = perform_operation(df)
    end_time = time.time()
    
    end_mem = process.memory_info().rss
    
    avg_time = (end_time - start_time) / num_iterations
    mem_used = (end_mem - start_mem) / (1024 * 1024)  # MB単位
    
    return avg_time, mem_used

# メイン実行部分
if __name__ == "__main__":
    # テストデータの生成（初回のみ実行）
    # generate_large_test_data()

    file_path = 'test_data_large.pkl'
    implementations = [
        ("No Cache", load_data_no_cache),
        ("lru_cache", load_data_lru_cache),
        ("joblib", load_data_joblib),
        ("diskcache", load_data_diskcache),
        ("cachetools", load_data_cachetools)
    ]

    print("Performance Test Results:")
    print("-------------------------")
    for name, func in implementations:
        # キャッシュをクリアし、初回ロード時間を測定
        if name == "lru_cache":
            load_data_lru_cache.cache_clear()
        elif name == "joblib":
            joblib_memory.clear()
        elif name == "diskcache":
            diskcache.clear()
        elif name == "cachetools":
            ttl_cache.clear()
        
        first_load_time, first_mem_usage = measure_performance(func, file_path, 1)
        print(f"{name}:")
        print(f"  First load time: {first_load_time:.4f} seconds")
        print(f"  First load memory usage: {first_mem_usage:.2f} MB")
        
        # 2回目以降のロード時間を測定
        cached_load_time, cached_mem_usage = measure_performance(func, file_path)
        print(f"  Cached load time: {cached_load_time:.4f} seconds")
        print(f"  Cached load memory usage: {cached_mem_usage:.2f} MB")
        print()

    # ファイルの更新をシミュレート
    print("Simulating file update...")
    with open(file_path, 'a') as f:
        f.write('dummy')  # ファイルを更新
    
    print("Performance after file update:")
    print("-------------------------------")
    for name, func in implementations:
        update_load_time, update_mem_usage = measure_performance(func, file_path, 1)
        print(f"{name}:")
        print(f"  Load time after update: {update_load_time:.4f} seconds")
        print(f"  Memory usage after update: {update_mem_usage:.2f} MB")
        print()

    # ファイルサイズの確認
    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB単位
    print(f"Test data file size: {file_size:.2f} MB")
----

=== 各実装オプションの性能測定結果
[options='header']
|===
| 実装オプション | 初回ロード時間 (秒) | 2回目以降ロード時間 (秒) | ファイル更新後ロード時間 (秒) 
| No Cache       | 0.0139              | 0.0039                   | 0.0056                         
| lru_cache      | 0.0052              | 0.0015                   | 0.0016                         
| joblib         | 0.0348              | 0.0057                   | 0.0071                         
| diskcache      | 0.0688              | 0.0036                   | 0.0050                         
| cachetools     | 0.0058              | 0.0015                   | 0.0052                         
|===

=== 性能分析
* lru_cacheとcachetoolsが最も高速で、ほぼ同等のパフォーマンスを示している
* joblibとdiskcacheは、初回ロード時間が長いが、2回目以降は改善される
* ファイル更新後のロード時間では、lru_cacheが最も高速だが、cachetoolsも良好なパフォーマンスを示している
* No Cacheは常に一定のパフォーマンスを示すが、キャッシュを使用する他の方法よりも遅い

=== 実装オプションの比較

=== メリット
[options='header', cols='1, 4']
|===
| 実装オプション | メリット 
| lru_cache      | - 最も高速<br>- 実装が簡単 
| joblib         | - ファイル更新検知が容易<br>- メモリマッピングによる大規模データの効率的な扱い 
| diskcache      | - 柔軟なキャッシュ管理<br>- SQLiteバックエンドによる信頼性 
| cachetools     | - 高速なパフォーマンス<br>- ファイル更新検知が容易<br>- TTLなどの追加機能あり 
|===

=== デメリット
[options='header', cols='1, 4']
|===
| 実装オプション | デメリット 
| lru_cache      | - メモリ使用量が多い可能性<br>- ファイル更新検知が難しい 
| joblib         | - 初回ロード時間が長い 
| diskcache      | - キャッシュ管理の複雑さ<br>- 初回ロード時間が最も長い 
| cachetools     | - カスタマイズにはやや複雑な実装が必要 
|===

=== 機能比較
[options='header', width='75%', cols="4, 1, 1, 1, 1"]
|===
| 機能 | lru_cache | joblib | diskcache | cachetools 
| メモリキャッシュ | ✓ | ✓ | ✓ | ✓ 
| ディスクキャッシュ | - | ✓ | ✓ | - 
| ファイル更新検知 | - | ✓ | ✓ | ✓* 
| メモリマッピング | - | ✓ | - | - 
| キャッシュサイズ制限 | ✓ | - | ✓ | ✓ 
| マルチスレッド対応 | - | ✓ | ✓ | ✓ 
| TTL (Time To Live) | - | - | ✓ | ✓ 
|===

== 推奨実装方針

=== 抽象化アプローチ

キャッシュ実装を抽象化し、異なるキャッシュ戦略を容易に切り替えられるようにする。

=== インターフェース設計

[source, python]
----
from abc import ABC, abstractmethod

class CacheManager(ABC):
    @abstractmethod
    def get_data(self, file_path):
        pass

    @abstractmethod
    def clear_cache(self):
        pass
----

=== 具体的な実装クラス

設計時に選択したcache戦略が後々も正解であり続ける保証は無い。柔軟にcacheライブラリを変更できるよう実装を行う。具体的には以下コード参照。

[source, python]
----
class JobLibCacheManager(CacheManager):
    def __init__(self, cache_dir='./joblib_cache'):
        self.memory = Memory(cache_dir, verbose=0)
        self.get_data = self.memory.cache(self._get_data)

    def get_data(self, file_path):
        return pd.read_pickle(file_path)

    def clear_cache(self):
        self.memory.clear()

class DiskCacheManager(CacheManager):
    def __init__(self, cache_dir='./diskcache_cache'):
        self.cache = Cache(cache_dir)

    def get_data(self, file_path):
        key = f'data:{file_path}'
        data = self.cache.get(key)
        if data is None:
            data = pd.read_pickle(file_path)
            self.cache.set(key, data)
        return data

    def clear_cache(self):
        self.cache.clear()

from cachetools import TTLCache, cached

class CacheToolsManager(CacheManager):
    def __init__(self, ttl=3600):
        self.ttl_cache = TTLCache(maxsize=1, ttl=ttl)

    def get_data(self, file_path):
        @cached(cache=self.ttl_cache, key=lambda fp: (fp, os.path.getmtime(fp)))
        def load_data(fp):
            return pd.read_pickle(fp)
        return load_data(file_path)

    def clear_cache(self):
        self.ttl_cache.clear()
----

=== 適用対象ファイル
[options='header', cols='1, 1, 3']
|===
| ファイル形式 | キャッシュ適用 | 理由 
| pickle形式（通常） | 適用する | 高速なロードと保存が可能で、キャッシュの恩恵を最大限に受けられる 
| pickle形式（更新用） | 適用しない | 更新処理であり、キャッシュ恩恵が薄い 
| Excel形式 | 適用しない | 都度新しいExcelファイルを取り込む運用を想定、キャッシュ恩恵なし 
| CSV形式 | 適用しない | CSVファイルは出力のみ利用、キャッシュ利用には適合しない 
|===
