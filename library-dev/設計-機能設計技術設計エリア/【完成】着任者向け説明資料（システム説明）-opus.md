# リファレンスDB

## 1. システムの全体像と目的

### 1.1 リファレンスデータの役割と重要性
リファレンスデータとは、組織全体で共有され、業務システムの基盤となる重要な情報です。部署情報や各種設定値など、業務を遂行する上で必要不可欠なマスタデータを集約し、一元的に管理することで、データの整合性と品質を保証します。

リファレンスデータを適切に管理することは、業務の効率化と意思決定の迅速化に直結します。各システムがバラバラにマスタデータを保持していると、データの不整合や重複が発生し、業務に支障をきたす恐れがあります。リファレンスデータを集中管理することで、このような問題を未然に防ぎ、業務の円滑化を図ることができます。

また、リファレンスデータは法令遵守やリスク管理の観点からも重要です。規制当局からの要請に迅速に対応したり、リスクを適切にコントロールしたりするためには、正確で信頼性の高いリファレンスデータが不可欠です。

以上のように、リファレンスデータは組織の業務基盤を支える重要な役割を担っています。本システムは、このリファレンスデータを一元管理し、その品質と整合性を保証するために構築されました。

### 1.2 システムが扱うデータの概要

#### 1.2.1 部署情報
部署情報は、組織の構造を表すデータです。部署コード、部署名称、上位部署、下位部署などの情報を含みます。部署情報は、従業員の所属管理、アクセス制御、権限管理など、様々な業務で利用されます。

#### 1.2.2 各種設定値
各種設定値は、業務システムの動作を制御するためのパラメータです。システムの機能や処理フローを柔軟に変更できるよう、設定値として外部管理されます。例えば、承認ルートの設定、メール通知の有無、バッチ処理の実行時間など、様々な設定値があります。

### 1.3 関連システムとのデータ連携の概要
リファレンスDBは、行内の様々なシステムに対してデータを提供します。主要な連携先は以下の通りです。

- 人事システム：従業員の所属情報を管理するために、部署情報を参照します。
- 認証システム：システムへのアクセス制御を行うために、部署情報と従業員情報を参照します。
- 会計システム：部署ごとの予算管理を行うために、部署情報を参照します。
- ワークフロー：申請・承認フローを制御するために、部署情報と承認者情報を参照します。

これらのシステムとの連携は、主にCSVファイルのやり取りによって行われます。リファレンスDBから必要なデータを抽出し、所定のフォーマットでファイル化して、SFTPで各システムに提供します。連携のタイミングは、日次や月次などの定期バッチ処理で行われるのが一般的です。

[plantuml]
----
@startuml
object "リファレンスDB" as refdb {
  部署情報
  各種設定値
}

object "人事システム" as hr
object "認証システム" as auth
object "会計システム" as acc
object "ワークフロー" as wf

refdb -right-> hr : 部署情報の提供
refdb -right-> auth : 部署情報と従業員情報の提供
refdb -down-> acc : 部署情報の提供
refdb -down-> wf : 部署情報と承認者情報の提供
@enduml
----

## 2. 業務フロー

### 2.1 申請部署からの申請フロー
リファレンスデータの更新は、以下の3つの部署からの申請に基づいて行われます。

#### 2.1.1 人事部
人事部は、行内の部署情報を管理する部署です。新しい部署の設置や既存部署の変更・廃止といった組織変更を主導します。人事部からの申請は、主に部署情報の更新に関するものです。

#### 2.1.2 国際事務企画室
国際事務企画室は、海外拠点の管理を担当する部署です。海外拠点の設置・変更・廃止に伴う部署情報の更新を申請します。

#### 2.1.3 関連会社
関連会社からの申請は、グループ会社の部署情報に関するものです。関連会社の組織変更に伴って、リファレンスデータの更新が必要になります。

これらの部署からの申請は、所定のフォーマットのExcelファイルに必要事項を記入して提出されます。申請内容の審査・承認を経た後、リファレンステーブルに反映されます。

### 2.2 申請データのフォーマットと内容
申請データのフォーマットは、申請部署ごとに異なります。人事部からの申請は「人事フォーム」、国際事務企画室からの申請は「国企フォーム」、関連会社からの申請は「関連フォーム」と呼ばれるExcelファイルに記入します。

各フォームには、以下のような情報が含まれます。

- 申請ID：申請を一意に識別するためのID
- 申請日：申請を行った日付
- 申請部署：申請を行った部署名
- 申請者：申請を行った担当者名
- 変更内容：新設、変更、廃止の区分
- 変更対象：変更対象の部署コード、部署名など
- 変更理由：変更を行う理由や背景
- 変更詳細：変更内容の詳細（例：新設の場合は新しい部署の情報、変更の場合は変更前後の情報）

これらの情報をもとに、リファレンステーブルの更新処理が行われます。

### 2.3 申請種別

#### 2.3.1 新設
新設は、新しい部署を組織に追加する場合の申請です。新しい部署コード、部署名、上位部署などの情報を申請フォームに記入します。

#### 2.3.2 変更
変更は、既存の部署の情報を変更する場合の申請です。部署名の変更、上位部署の変更、組織階層の変更などが該当します。変更前の情報と変更後の情報を申請フォームに記入します。

#### 2.3.3 廃止
廃止は、既存の部署を組織から削除する場合の申請です。廃止対象の部署コードを申請フォームに記入します。廃止された部署の情報は、リファレンステーブルから削除されます。

<activity-diagram>
[plantuml]
----
@startuml
start
:申請部署が申請フォームを作成;
:申請部署が申請フォームを提出;
if (申請内容に問題がある?) then (yes)
  :申請内容を修正;
  :再提出;
else (no)
  :申請を受理;
  if (申請種別は?) then (新設)
    :新設の場合の処理;
  else if (変更) then
    :変更の場合の処理;
  else (廃止)
    :廃止の場合の処理;
  endif
  :リファレンステーブルを更新;
endif
stop
@enduml
----
</activity-diagram>

## 3. システムアーキテクチャ

### 3.1 システムを構成する4つのフェーズ
本システムは、以下の4つのフェーズで構成されます。

#### 3.1.1 一括申請
一括申請フェーズでは、申請部署から提出されたExcelファイルを一括して取り込みます。取り込んだデータに対してバリデーションチェックを行い、フォーマットや入力値の不備を検出します。

#### 3.1.2 受付
受付フェーズでは、一括申請フェーズで取り込んだデータに対して、前処理を行います。具体的には、データのクレンジング、標準化、変換などを行い、後続のパターン編集フェーズで処理しやすい形式にデータを整えます。また、受付ディシジョンテーブルを用いて、データの条件に応じた適切なFacadeを呼び出します。

#### 3.1.3 パターン編集
パターン編集フェーズでは、受け付けた申請データをリファレンステーブルの更新に必要な形式に変換します。具体的には、新規明細レコード、更新明細レコード、廃止明細レコードを作成します。これらの処理は、パターン編集ディシジョンテーブルを用いて、データの条件に応じて適切なFacadeを呼び出すことで実現します。

#### 3.1.4 反映・送信
反映・送信フェーズでは、パターン編集フェーズで作成した更新明細レコードを使って、リファレンステーブルを更新します。更新が完了したら、関連システムへのデータ連携を行います。

### 3.2 データの流れと永続化

#### 3.2.1 pandas DataFrame
一括申請フェーズで取り込んだExcelデータは、pandas DataFrameに変換されます。DataFrameは、データの加工や検証に適したデータ構造で、高速な処理が可能です。

#### 3.2.2 pickle形式
DataFrameに変換されたデータは、pickle形式で永続化されます。pickleは、Pythonのオブジェクトを直列化・非直列化するための仕組みです。pickleを使うことで、DataFrameをファイルに保存し、後から読み込んで再利用することができます。

<package-diagram>
[plantuml]
----
@startuml
package "一括申請" {
  [Excelデータ取込] --> [バリデーションチェック]
  [バリデーションチェック] --> [DataFrame変換]
  [DataFrame変換] --> [一括申請データ保存]
}

package "受付" {
  [一括申請データ読込] --> [データクレンジング]
  [データクレンジング] --> [データ標準化]
  [データ標準化] --> [データ変換]
  [データ変換] --> [受付ディシジョンテーブル]
  [受付ディシジョンテーブル] --> [受付Facade呼び出し]
  [受付Facade呼び出し] --> [受付データ保存]
}

package "パターン編集" {
  [受付データ読込] --> [新規明細レコード作成]
  [受付データ読込] --> [更新明細レコード作成]
  [受付データ読込] --> [廃止明細レコード作成]
  [新規明細レコード作成] --> [パターン編集ディシジョンテーブル]
  [更新明細レコード作成] --> [パターン編集ディシジョンテーブル]
  [廃止明細レコード作成] --> [パターン編集ディシジョンテーブル]
  [パターン編集ディシジョンテーブル] --> [パターン編集Facade呼び出し]
  [パターン編集Facade呼び出し] --> [パターン編集データ保存]
}

package "反映・送信" {
  [パターン編集データ読込] --> [リファレンステーブル更新]
  [リファレンステーブル更新] --> [関連システムへのデータ連携]
}

database "リファレンステーブル" {
  frame "部署情報" {
    [部署情報データ]
  }
  frame "設定値" {
    [設定値データ]
  }
}

[一括申請データ保存] --> [一括申請データ読込] : pickle経由でデータ受け渡し
[受付データ保存] --> [受付データ読込] : pickle経由でデータ受け渡し
[パターン編集データ保存] --> [パターン編集データ読込] : pickle経由でデータ受け渡し

[リファレンステーブル更新] --> [部署情報データ]
[リファレンステーブル更新] --> [設定値データ]
@enduml
----
</package-diagram>

## 4. 各フェーズの詳細

### 4.1 一括申請
一括申請フェーズは、以下の3つの処理で構成されます。

#### 4.1.1 申請データの取込み
申請部署から提出されたExcelファイルを読み込み、データを取り込みます。Excelファイルのフォーマットは、申請部署ごとに異なるため、それぞれに対応したデータ取込み処理が必要です。

#### 4.1.2 バリデーション
取り込んだデータに対して、以下の2種類のバリデーションチェックを行います。

- カラム単体のバリデーション
  - 必須項目の入力チェック
  - データ型のチェック（数値、日付、文字列など）
  - 文字数のチェック
  - 入力値の範囲チェック
- 同一シリーズ内の他カラムや外部データを使った整合性チェック

コードの妥当性チェック（部署コード、設定値コードなど）
依存関係のチェック（上位部署の存在チェックなど）

これらのバリデーションチェックは、pydanticを使用して実装します。カラム単体のバリデーションはpydanticのモデル定義で行い、整合性チェックは関数を呼び出して行います。
バリデーションエラーが発生した場合は、エラー内容を申請部署にフィードバックし、修正を依頼します。

#### 4.1.3 データ変換
バリデーションを通過したデータを、pandas DataFrameに変換します。この際、以下のような前処理を行います。

文字コードの統一（UTF-8など）
日付や数値のデータ型変換
不要な項目の削除
項目名の統一

変換したDataFrameは、pickle形式で保存し、次の受付フェーズに引き継ぎます。


### 4.2 受付
受付フェーズは、以下の処理で構成されます。

#### 4.2.1 データクレンジング
一括申請フェーズで取り込んだデータに対して、クレンジング処理を行います。具体的には、以下のような処理を行います。

欠損値の補完
異常値の除外
重複データの削除

#### 4.2.2 データ標準化
クレンジング済みのデータに対して、標準化処理を行います。具体的には、以下のような処理を行います。

文字列の統一（全角・半角、大文字・小文字など）
コードの統一（部署コード、設定値コードなど）
日付や数値の表現統一

#### 4.2.3 データ変換
標準化済みのデータに対して、後続のパターン編集フェーズで処理しやすいようにデータ変換を行います。

#### 4.2.4 受付ディシジョンテーブルによる分岐制御
受付フェーズでは、データの内容に応じて適切な処理を行うために、受付ディシジョンテーブルを用います。受付ディシジョンテーブルには、データの全カラムに対する条件と、それに対応するFacadeが定義されています。
受付処理では、各レコードの全カラムの値を条件とマッチングし、全ての条件を満たした場合に対応するFacadeを呼び出します。

#### 4.2.5 同一課Grに対する申請のマージ
同一課Grに対する申請が複数存在する場合、それらを1つの申請にマージします。マージの際は、申請にある明細を優先し、システム内で生成された明細は破棄します。明細の作成タイミングは、ULIDを使って判断します。

### 4.3 パターン編集
パターン編集フェーズは、以下の処理で構成されます。

#### 4.3.1 更新明細レコードの作成
受付フェーズを通過したデータから、リファレンステーブルの更新に必要な情報を抽出し、更新明細レコードを作成します。更新明細レコードには、以下の情報が含まれます。

申請種別（新設、変更、廃止）
対象の部署コード
変更前の情報
変更後の情報

#### 4.3.2 パターン編集ディシジョンテーブルによる分岐制御
パターン編集フェーズでは、受付フェーズと同様にパターン編集ディシジョンテーブルを用いて処理の分岐制御を行います。更新明細レコードの内容に応じて、適切なFacadeを呼び出し、必要な処理を行います。

### 4.4 反映・送信
反映・送信フェーズは、以下の処理で構成されます。

#### 4.4.1 リファレンステーブル更新
パターン編集フェーズで作成した更新明細レコードを使って、リファレンステーブルを更新します。更新の際は、以下の点に留意します。

トランザクション管理を行い、更新処理が失敗した場合はロールバックする
更新後のデータに不整合がないかチェックする
更新履歴を記録する

#### 4.4.2 関連システムへのデータ連携
リファレンステーブルの更新が完了したら、関連システムへのデータ連携を行います。連携はCSVファイルをSFTPで送信することで行います。
連携の実行タイミングは、システムごとに設定されたスケジュールに従います。
<sequence-diagram>
[plantuml]
----
@startuml
participant "申請部署" as dept
participant "一括申請" as bulk
participant "受付" as accept
participant "パターン編集" as pattern
participant "反映・送信" as reflect
database "リファレンステーブル" as reftable
participant "関連システム" as related
dept -> bulk : 申請フォームの提出
bulk -> bulk : バリデーションチェック
bulk -> bulk : DataFrame変換
bulk -> accept : 申請データの引き渡し
accept -> accept : データクレンジング
accept -> accept : データ標準化
accept -> accept : データ変換
accept -> accept : 受付ディシジョンテーブルによる分岐制御
accept -> accept : 同一課Grに対する申請のマージ
accept -> pattern : 申請データの引き渡し
pattern -> pattern : 更新明細レコードの作成
pattern -> pattern : パターン編集ディシジョンテーブルによる分岐制御
pattern -> reflect : 更新明細レコードの引き渡し
reflect -> reftable : リファレンステーブル更新
reftable --> reflect : 更新結果の返却
reflect -> related : データ連携の実行
@enduml
----
</sequence-diagram>

## 5. 非機能要件
### 5.1 パフォーマンス

一括申請フェーズのデータ取込みは、1万件以上の申請データを30分以内に処理できること
反映・送信フェーズのリファレンステーブル更新は、1万件以上の更新を1時間以内に完了できること
関連システムへのデータ連携は、システムごとに定められたSLAを満たすこと

### 5.2 セキュリティ

リファレンステーブルへのアクセス権限は、業務上必要な担当者に限定し、定期的に棚卸しを行うこと
申請データや連携データは、暗号化された状態で保存・転送すること
システムへのアクセスは、IDとパスワードによる認証を必須とすること

### 5.3 可用性

システムの稼働時間は、原則として24時間365日とする
計画停止は、年2回までとし、1回あたり24時間以内に収めること
障害発生時は、24時間以内に復旧できる体制を整えること
東京Rでの障害発生時は原則回復待ちとなる、長期サービス停止の場合は大阪Rでの立ち上げを行うよう、発生時に対応する

### 5.4 被災要件
被災要件はなし
SWD及び人事部とも合意済

## 6. 移行計画
### 6.1 既存システムからの移行手順

既存システムのデータを抽出する
抽出したデータをクレンジングし、新システムのフォーマットに変換する
変換したデータを新システムに取り込む
新システムでデータの整合性をチェックする
問題がなければ、新システムでのデータ運用を開始する

### 6.2 移行時のデータ変換、整合性担保方法

既存システムのデータ形式と新システムのデータ形式のマッピングを定義する
変換処理のテストを十分に行い、データ欠落や不整合が発生しないことを確認する
移行後のデータと既存システムのデータを突合し、整合性を確認する
リファレンステーブルには、過去の運用による不備データが含まれている可能性があるため、移行対象を絞り込んだ上で、必要に応じてデータを修正する

### 6.3 移行後の並行稼働期間と切り替え手順

移行後、1ヶ月間は既存システムと新システムを並行稼働させる
並行稼働期間中は、両システムのデータを比較し、不整合がないことを確認する
不整合がある場合は、原因を調査し、必要に応じてデータを修正する
並行稼働期間終了後、既存システムを停止し、新システムに完全移行する

## 7. 運用・保守
### 7.1 運用手順
リファレンスデータの更新は、以下の手順で行います。

#### 7.1.1 申請受付

申請部署が申請フォームに必要事項を記入する
申請フォームを所定の方法で提出する
申請データを一括申請フェーズで取り込む

#### 7.1.2 データ更新

受付フェーズで申請内容を精査し、不備があれば申請部署に差し戻す
パターン編集フェーズで更新明細レコードを作成する
反映・送信フェーズでリファレンステーブルを更新する

#### 7.1.3 関連システム連携

リファレンステーブルの更新が完了したら、関連システムへのデータ連携を実行する
連携結果に問題がないことを確認する
問題があれば、原因を調査し、必要に応じて再連携を行う

### 7.2 モニタリングと障害対応

システムの稼働状況を常時モニタリングし、異常を検知する
異常検知時は、速やかに原因を調査し、障害を解消する
障害の影響範囲を特定し、関係部署に連絡する
障害の原因と対応内容を記録し、再発防止策を講じる

### 7.3 保守作業
#### 7.3.1 定期メンテナンス

システムのパッチ適用やバージョンアップは、年2回の定期メンテナンス時に実施する
定期メンテナンスの実施日時は、関係部署と調整の上、決定する
メンテナンス実施前に、システムの利用者に通知を行う

#### 7.3.2 パラメータ変更

システムのパラメータ変更は、申請に基づいて行う
パラメータ変更の申請は、所定の様式で行う
変更申請は、関係部署との調整を経て、承認される
承認されたパラメータ変更は、速やかにシステムに反映する

### 7.4 一括申請、受付、パターン編集のリグレ実行

申請データの取込み、精査、編集は、本番環境とは別のリグレ環境で行う
リグレ環境での処理結果を確認し、問題がなければ本番環境に反映する
リグレ環境と本番環境のデータ整合性を確認する

### 7.5 本番環境での反映・送信の実行

反映・送信フェーズの処理は、本番環境で実行する
本番環境での更新処理は、許可された担当者のみが実行できる
更新処理の実行記録を残し、トレーサビリティを確保する

### 7.6 Validation/整合性チェックのモード
システムには、以下の2つのモードを用意する。

#### 7.6.1 チェックモード

バリデーションや整合性チェックでエラーが発生した場合、処理を中断する
エラーの内容を画面やログに出力し、利用者に通知する
利用者は、エラーを修正した上で、再処理を実行する

#### 7.6.2 承認済モード

バリデーションや整合性チェックでエラーが発生しても、処理を継続する
エラーの内容は、画面やログに警告として出力する
承認済モードは、システム管理者のみが実行できる

以上で、リファレンスDB説明資料の作成を終了します。
