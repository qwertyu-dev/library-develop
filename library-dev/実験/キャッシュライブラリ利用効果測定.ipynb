{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /developer/library_dev/.venv/lib/python3.11/site-packages (1.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting diskcache\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: diskcache\n",
      "Successfully installed diskcache-5.6.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib\n",
    "!pip install diskcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Memory(location=./joblib_cache/joblib)]: Flushing completely the cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated test data: 20000 rows, 50 columns\n",
      "          id           timestamp   value_2   value_3   value_4   value_5  \\\n",
      "0          0 2023-01-01 00:00:00  0.374540  0.729998  0.298912  0.741555   \n",
      "1          1 2023-01-01 01:00:00  0.950714  0.184512  0.094818  0.881102   \n",
      "2          2 2023-01-01 02:00:00  0.731994  0.346640  0.126359  0.463180   \n",
      "3          3 2023-01-01 03:00:00  0.598658  0.663281  0.180671  0.289179   \n",
      "4          4 2023-01-01 04:00:00  0.156019  0.482089  0.203653  0.318847   \n",
      "...      ...                 ...       ...       ...       ...       ...   \n",
      "19995  19995 2025-04-13 03:00:00  0.877039  0.754034  0.966141  0.322129   \n",
      "19996  19996 2025-04-13 04:00:00  0.046814  0.764527  0.373240  0.374626   \n",
      "19997  19997 2025-04-13 05:00:00  0.303698  0.269569  0.304675  0.381702   \n",
      "19998  19998 2025-04-13 06:00:00  0.443320  0.434320  0.407363  0.129632   \n",
      "19999  19999 2025-04-13 07:00:00  0.172265  0.487424  0.522833  0.947287   \n",
      "\n",
      "        value_6   value_7   value_8   value_9  ...  value_40  value_41  \\\n",
      "0      0.818164  0.580779  0.129754  0.128320  ...  0.526411  0.513781   \n",
      "1      0.145270  0.526972  0.539726  0.774723  ...  0.332601  0.805555   \n",
      "2      0.946464  0.351037  0.615386  0.615812  ...  0.240792  0.776524   \n",
      "3      0.843224  0.493213  0.507705  0.647443  ...  0.275440  0.429795   \n",
      "4      0.918853  0.365097  0.517597  0.245727  ...  0.730293  0.862142   \n",
      "...         ...       ...       ...       ...  ...       ...       ...   \n",
      "19995  0.792305  0.001500  0.787718  0.753924  ...  0.299644  0.551363   \n",
      "19996  0.779253  0.289755  0.180142  0.610521  ...  0.083213  0.110851   \n",
      "19997  0.674453  0.432260  0.530251  0.295685  ...  0.183208  0.966074   \n",
      "19998  0.499447  0.023856  0.103144  0.792516  ...  0.654961  0.780313   \n",
      "19999  0.389908  0.453840  0.503319  0.458133  ...  0.235299  0.143615   \n",
      "\n",
      "       value_42  value_43  value_44  value_45  value_46  value_47  value_48  \\\n",
      "0      0.470122  0.320349  0.021112  0.198872  0.739340  0.177220  0.485739   \n",
      "1      0.620380  0.548532  0.113269  0.965902  0.828619  0.425793  0.534567   \n",
      "2      0.808050  0.958103  0.969039  0.426369  0.723422  0.433131  0.080541   \n",
      "3      0.204902  0.813145  0.110281  0.918924  0.334682  0.382641  0.395657   \n",
      "4      0.012230  0.767878  0.451800  0.112728  0.024598  0.018041  0.682932   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "19995  0.295836  0.944916  0.485900  0.031471  0.817829  0.023044  0.238972   \n",
      "19996  0.989490  0.577855  0.675263  0.342927  0.277422  0.003599  0.728179   \n",
      "19997  0.986305  0.018740  0.075983  0.482797  0.424015  0.085113  0.727007   \n",
      "19998  0.313713  0.673458  0.268987  0.379192  0.764837  0.524930  0.654085   \n",
      "19999  0.796553  0.428879  0.669276  0.894147  0.801947  0.227003  0.178011   \n",
      "\n",
      "       value_49  \n",
      "0      0.278399  \n",
      "1      0.842012  \n",
      "2      0.310759  \n",
      "3      0.200514  \n",
      "4      0.340968  \n",
      "...         ...  \n",
      "19995  0.118265  \n",
      "19996  0.007082  \n",
      "19997  0.741272  \n",
      "19998  0.174076  \n",
      "19999  0.094457  \n",
      "\n",
      "[20000 rows x 50 columns]\n",
      "Performance Test Results:\n",
      "-------------------------\n",
      "No Cache:\n",
      "  First load time: 0.0012 seconds\n",
      "  First load memory usage: 0.00 MB\n",
      "  Cached load time: 0.0006 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "lru_cache:\n",
      "  First load time: 0.0008 seconds\n",
      "  First load memory usage: 0.00 MB\n",
      "  Cached load time: 0.0000 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "joblib:\n",
      "  First load time: 0.0092 seconds\n",
      "  First load memory usage: 0.00 MB\n",
      "  Cached load time: 0.0019 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "diskcache:\n",
      "  First load time: 0.0188 seconds\n",
      "  First load memory usage: 0.00 MB\n",
      "  Cached load time: 0.0007 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "Test data file size: 7.63 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from joblib import Memory\n",
    "from diskcache import Cache\n",
    "\n",
    "# テストデータの生成（既に生成済みの場合はスキップ可能）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def generate_test_data(n_rows=20000, n_cols=50):\n",
    "    np.random.seed(42)\n",
    "    data = {\n",
    "        'id': range(n_rows),\n",
    "        'timestamp': pd.date_range(start='2023-01-01', periods=n_rows, freq='H')\n",
    "    }\n",
    "    \n",
    "    # 追加の数値カラム\n",
    "    for i in range(2, n_cols):\n",
    "        data[f'value_{i}'] = np.random.rand(n_rows)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle('test_data_large.pkl')\n",
    "    print(f\"Generated test data: {n_rows} rows, {n_cols} columns\")\n",
    "    print(df)\n",
    "\n",
    "generate_test_data()\n",
    "\n",
    "from functools import lru_cache\n",
    "from joblib import Memory\n",
    "from diskcache import Cache\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "# キャッシュ実装\n",
    "@lru_cache(maxsize=1)\n",
    "def load_data_lru_cache(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "joblib_memory = Memory('./joblib_cache', verbose=0)\n",
    "@joblib_memory.cache\n",
    "def load_data_joblib(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "diskcache = Cache('./diskcache_cache')\n",
    "def load_data_diskcache(file_path):\n",
    "    key = f'data:{file_path}'\n",
    "    data = diskcache.get(key)\n",
    "    if data is None:\n",
    "        data = pd.read_pickle(file_path)\n",
    "        diskcache.set(key, data)\n",
    "    return data\n",
    "\n",
    "def load_data_no_cache(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "# 性能測定関数\n",
    "def measure_performance(load_func, file_path, num_iterations=10):\n",
    "    gc.collect()  # ガベージコレクションを実行\n",
    "    \n",
    "    # メモリ使用量の測定（開始時）\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_mem = process.memory_info().rss\n",
    "\n",
    "    # 実行時間の測定\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        df = load_func(file_path)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # メモリ使用量の測定（終了時）\n",
    "    end_mem = process.memory_info().rss\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_iterations\n",
    "    mem_used = (end_mem - start_mem) / (1024 * 1024)  # MB単位\n",
    "    \n",
    "    return avg_time, mem_used\n",
    "\n",
    "# テスト実行\n",
    "file_path = 'test_data_large.pkl'\n",
    "implementations = [\n",
    "    (\"No Cache\", load_data_no_cache),\n",
    "    (\"lru_cache\", load_data_lru_cache),\n",
    "    (\"joblib\", load_data_joblib),\n",
    "    (\"diskcache\", load_data_diskcache)\n",
    "]\n",
    "\n",
    "print(\"Performance Test Results:\")\n",
    "print(\"-------------------------\")\n",
    "for name, func in implementations:\n",
    "    # キャッシュをクリアし、初回ロード時間を測定\n",
    "    if name == \"lru_cache\":\n",
    "        load_data_lru_cache.cache_clear()\n",
    "    elif name == \"joblib\":\n",
    "        joblib_memory.clear()\n",
    "    elif name == \"diskcache\":\n",
    "        diskcache.clear()\n",
    "    \n",
    "    first_load_time, first_mem_usage = measure_performance(func, file_path, 1)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  First load time: {first_load_time:.4f} seconds\")\n",
    "    print(f\"  First load memory usage: {first_mem_usage:.2f} MB\")\n",
    "    \n",
    "    # 2回目以降のロード時間を測定\n",
    "    cached_load_time, cached_mem_usage = measure_performance(func, file_path)\n",
    "    print(f\"  Cached load time: {cached_load_time:.4f} seconds\")\n",
    "    print(f\"  Cached load memory usage: {cached_mem_usage:.2f} MB\")\n",
    "    print()\n",
    "\n",
    "# ファイルサイズの確認\n",
    "file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB単位\n",
    "print(f\"Test data file size: {file_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated test data: 30000 rows, 100 columns\n",
      "Performance Test Results:\n",
      "-------------------------\n",
      "No Cache:\n",
      "  First load time: 0.0058 seconds\n",
      "  First load memory usage: 0.00 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Memory(location=./joblib_cache/joblib)]: Flushing completely the cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cached load time: 0.0039 seconds\n",
      "  Cached load memory usage: 6.44 MB\n",
      "\n",
      "lru_cache:\n",
      "  First load time: 0.0122 seconds\n",
      "  First load memory usage: 22.17 MB\n",
      "  Cached load time: 0.0014 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "joblib:\n",
      "  First load time: 0.0440 seconds\n",
      "  First load memory usage: 38.41 MB\n",
      "  Cached load time: 0.0054 seconds\n",
      "  Cached load memory usage: 6.57 MB\n",
      "\n",
      "diskcache:\n",
      "  First load time: 0.0757 seconds\n",
      "  First load memory usage: 22.30 MB\n",
      "  Cached load time: 0.0038 seconds\n",
      "  Cached load memory usage: 22.42 MB\n",
      "\n",
      "Test data file size: 22.89 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from joblib import Memory\n",
    "from diskcache import Cache\n",
    "\n",
    "# テストデータの生成\n",
    "def generate_large_test_data(n_rows=30000, n_cols=100):\n",
    "    np.random.seed(42)\n",
    "    data = {\n",
    "        'id': np.random.randint(0, 1000, n_rows),\n",
    "        'timestamp': pd.date_range(start='2023-01-01', periods=n_rows, freq='S')\n",
    "    }\n",
    "    \n",
    "    for i in range(2, n_cols):\n",
    "        data[f'value_{i}'] = np.random.rand(n_rows)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle('test_data_large.pkl')\n",
    "    print(f\"Generated test data: {n_rows} rows, {n_cols} columns\")\n",
    "\n",
    "# キャッシュ実装\n",
    "@lru_cache(maxsize=1)\n",
    "def load_data_lru_cache(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "joblib_memory = Memory('./joblib_cache', verbose=0)\n",
    "@joblib_memory.cache\n",
    "def load_data_joblib(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "diskcache = Cache('./diskcache_cache')\n",
    "def load_data_diskcache(file_path):\n",
    "    key = f'data:{file_path}'\n",
    "    data = diskcache.get(key)\n",
    "    if data is None:\n",
    "        data = pd.read_pickle(file_path)\n",
    "        diskcache.set(key, data)\n",
    "    return data\n",
    "\n",
    "def load_data_no_cache(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "# 複雑な操作の例\n",
    "def perform_operation(df):\n",
    "    result = df.groupby('id').agg({\n",
    "        'value_2': 'mean',\n",
    "        'value_3': 'sum',\n",
    "        'value_4': 'max',\n",
    "        'value_5': 'min'\n",
    "    })\n",
    "    return result\n",
    "\n",
    "# パフォーマンス測定関数\n",
    "def measure_performance(load_func, file_path, num_iterations=100):\n",
    "    gc.collect()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_mem = process.memory_info().rss\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        df = load_func(file_path)\n",
    "        result = perform_operation(df)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    end_mem = process.memory_info().rss\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_iterations\n",
    "    mem_used = (end_mem - start_mem) / (1024 * 1024)  # MB単位\n",
    "    \n",
    "    return avg_time, mem_used\n",
    "\n",
    "# メイン実行部分\n",
    "if __name__ == \"__main__\":\n",
    "    # テストデータの生成（初回のみ実行）\n",
    "    generate_large_test_data()\n",
    "\n",
    "    file_path = 'test_data_large.pkl'\n",
    "    implementations = [\n",
    "        (\"No Cache\", load_data_no_cache),\n",
    "        (\"lru_cache\", load_data_lru_cache),\n",
    "        (\"joblib\", load_data_joblib),\n",
    "        (\"diskcache\", load_data_diskcache)\n",
    "    ]\n",
    "\n",
    "    print(\"Performance Test Results:\")\n",
    "    print(\"-------------------------\")\n",
    "    for name, func in implementations:\n",
    "        # キャッシュをクリアし、初回ロード時間を測定\n",
    "        if name == \"lru_cache\":\n",
    "            load_data_lru_cache.cache_clear()\n",
    "        elif name == \"joblib\":\n",
    "            joblib_memory.clear()\n",
    "        elif name == \"diskcache\":\n",
    "            diskcache.clear()\n",
    "        \n",
    "        first_load_time, first_mem_usage = measure_performance(func, file_path, 1)\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  First load time: {first_load_time:.4f} seconds\")\n",
    "        print(f\"  First load memory usage: {first_mem_usage:.2f} MB\")\n",
    "        \n",
    "        # 2回目以降のロード時間を測定\n",
    "        cached_load_time, cached_mem_usage = measure_performance(func, file_path)\n",
    "        print(f\"  Cached load time: {cached_load_time:.4f} seconds\")\n",
    "        print(f\"  Cached load memory usage: {cached_mem_usage:.2f} MB\")\n",
    "        print()\n",
    "\n",
    "    # ファイルサイズの確認\n",
    "    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB単位\n",
    "    print(f\"Test data file size: {file_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cachetools\n",
      "  Downloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: cachetools\n",
      "Successfully installed cachetools-5.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cachetools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Test Results:\n",
      "-------------------------\n",
      "No Cache:\n",
      "  First load time: 0.0139 seconds\n",
      "  First load memory usage: 22.16 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Memory(location=./joblib_cache/joblib)]: Flushing completely the cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cached load time: 0.0040 seconds\n",
      "  Cached load memory usage: 22.43 MB\n",
      "\n",
      "lru_cache:\n",
      "  First load time: 0.0052 seconds\n",
      "  First load memory usage: 0.00 MB\n",
      "  Cached load time: 0.0015 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "joblib:\n",
      "  First load time: 0.0360 seconds\n",
      "  First load memory usage: 15.98 MB\n",
      "  Cached load time: 0.0057 seconds\n",
      "  Cached load memory usage: 6.57 MB\n",
      "\n",
      "diskcache:\n",
      "  First load time: 0.0637 seconds\n",
      "  First load memory usage: 0.02 MB\n",
      "  Cached load time: 0.0042 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "cachetools:\n",
      "  First load time: 0.0065 seconds\n",
      "  First load memory usage: 0.00 MB\n",
      "  Cached load time: 0.0015 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "Test data file size: 22.89 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from joblib import Memory\n",
    "from diskcache import Cache\n",
    "from cachetools import TTLCache, cached\n",
    "\n",
    "# テストデータの生成\n",
    "def generate_large_test_data(n_rows=1000000, n_cols=150):\n",
    "    np.random.seed(42)\n",
    "    data = {\n",
    "        'id': np.random.randint(0, 1000, n_rows),\n",
    "        'timestamp': pd.date_range(start='2023-01-01', periods=n_rows, freq='S')\n",
    "    }\n",
    "    \n",
    "    for i in range(2, n_cols):\n",
    "        data[f'value_{i}'] = np.random.rand(n_rows)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle('test_data_large.pkl')\n",
    "    print(f\"Generated test data: {n_rows} rows, {n_cols} columns\")\n",
    "\n",
    "# キャッシュ実装\n",
    "@lru_cache(maxsize=1)\n",
    "def load_data_lru_cache(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "joblib_memory = Memory('./joblib_cache', verbose=0)\n",
    "@joblib_memory.cache\n",
    "def load_data_joblib(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "diskcache = Cache('./diskcache_cache')\n",
    "def load_data_diskcache(file_path):\n",
    "    key = f'data:{file_path}'\n",
    "    data = diskcache.get(key)\n",
    "    if data is None:\n",
    "        data = pd.read_pickle(file_path)\n",
    "        diskcache.set(key, data)\n",
    "    return data\n",
    "\n",
    "def load_data_no_cache(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "# cachetoolsの実装\n",
    "ttl_cache = TTLCache(maxsize=1, ttl=3600)  # 1時間のTTL\n",
    "\n",
    "@cached(cache=ttl_cache)\n",
    "def load_data_cachetools(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "# 複雑な操作の例\n",
    "def perform_operation(df):\n",
    "    result = df.groupby('id').agg({\n",
    "        'value_2': 'mean',\n",
    "        'value_3': 'sum',\n",
    "        'value_4': 'max',\n",
    "        'value_5': 'min'\n",
    "    })\n",
    "    return result\n",
    "\n",
    "# パフォーマンス測定関数\n",
    "def measure_performance(load_func, file_path, num_iterations=100):\n",
    "    gc.collect()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_mem = process.memory_info().rss\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        df = load_func(file_path)\n",
    "        result = perform_operation(df)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    end_mem = process.memory_info().rss\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_iterations\n",
    "    mem_used = (end_mem - start_mem) / (1024 * 1024)  # MB単位\n",
    "    \n",
    "    return avg_time, mem_used\n",
    "\n",
    "# メイン実行部分\n",
    "if __name__ == \"__main__\":\n",
    "    # テストデータの生成（初回のみ実行）\n",
    "    # generate_large_test_data()\n",
    "\n",
    "    file_path = 'test_data_large.pkl'\n",
    "    implementations = [\n",
    "        (\"No Cache\", load_data_no_cache),\n",
    "        (\"lru_cache\", load_data_lru_cache),\n",
    "        (\"joblib\", load_data_joblib),\n",
    "        (\"diskcache\", load_data_diskcache),\n",
    "        (\"cachetools\", load_data_cachetools)\n",
    "    ]\n",
    "\n",
    "    print(\"Performance Test Results:\")\n",
    "    print(\"-------------------------\")\n",
    "    for name, func in implementations:\n",
    "        # キャッシュをクリアし、初回ロード時間を測定\n",
    "        if name == \"lru_cache\":\n",
    "            load_data_lru_cache.cache_clear()\n",
    "        elif name == \"joblib\":\n",
    "            joblib_memory.clear()\n",
    "        elif name == \"diskcache\":\n",
    "            diskcache.clear()\n",
    "        elif name == \"cachetools\":\n",
    "            ttl_cache.clear()\n",
    "        \n",
    "        first_load_time, first_mem_usage = measure_performance(func, file_path, 1)\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  First load time: {first_load_time:.4f} seconds\")\n",
    "        print(f\"  First load memory usage: {first_mem_usage:.2f} MB\")\n",
    "        \n",
    "        # 2回目以降のロード時間を測定\n",
    "        cached_load_time, cached_mem_usage = measure_performance(func, file_path)\n",
    "        print(f\"  Cached load time: {cached_load_time:.4f} seconds\")\n",
    "        print(f\"  Cached load memory usage: {cached_mem_usage:.2f} MB\")\n",
    "        print()\n",
    "\n",
    "    # ファイルサイズの確認\n",
    "    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB単位\n",
    "    print(f\"Test data file size: {file_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Test Results:\n",
      "-------------------------\n",
      "No Cache:\n",
      "  First load time: 0.0139 seconds\n",
      "  First load memory usage: 22.17 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Memory(location=./joblib_cache/joblib)]: Flushing completely the cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cached load time: 0.0039 seconds\n",
      "  Cached load memory usage: 22.43 MB\n",
      "\n",
      "lru_cache:\n",
      "  First load time: 0.0052 seconds\n",
      "  First load memory usage: 0.00 MB\n",
      "  Cached load time: 0.0015 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "joblib:\n",
      "  First load time: 0.0348 seconds\n",
      "  First load memory usage: 15.98 MB\n",
      "  Cached load time: 0.0057 seconds\n",
      "  Cached load memory usage: 6.57 MB\n",
      "\n",
      "diskcache:\n",
      "  First load time: 0.0688 seconds\n",
      "  First load memory usage: 0.02 MB\n",
      "  Cached load time: 0.0036 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "cachetools:\n",
      "  First load time: 0.0058 seconds\n",
      "  First load memory usage: 0.00 MB\n",
      "  Cached load time: 0.0015 seconds\n",
      "  Cached load memory usage: 0.00 MB\n",
      "\n",
      "Simulating file update...\n",
      "Performance after file update:\n",
      "-------------------------------\n",
      "No Cache:\n",
      "  Load time after update: 0.0056 seconds\n",
      "  Memory usage after update: 0.00 MB\n",
      "\n",
      "lru_cache:\n",
      "  Load time after update: 0.0016 seconds\n",
      "  Memory usage after update: 0.00 MB\n",
      "\n",
      "joblib:\n",
      "  Load time after update: 0.0071 seconds\n",
      "  Memory usage after update: 0.00 MB\n",
      "\n",
      "diskcache:\n",
      "  Load time after update: 0.0050 seconds\n",
      "  Memory usage after update: 0.00 MB\n",
      "\n",
      "cachetools:\n",
      "  Load time after update: 0.0052 seconds\n",
      "  Memory usage after update: 0.00 MB\n",
      "\n",
      "Test data file size: 22.89 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from joblib import Memory\n",
    "from diskcache import Cache\n",
    "from cachetools import TTLCache, cached\n",
    "\n",
    "# テストデータの生成\n",
    "def generate_large_test_data(n_rows=1000000, n_cols=50):\n",
    "    np.random.seed(42)\n",
    "    data = {\n",
    "        'id': np.random.randint(0, 1000, n_rows),\n",
    "        'timestamp': pd.date_range(start='2023-01-01', periods=n_rows, freq='S')\n",
    "    }\n",
    "    \n",
    "    for i in range(2, n_cols):\n",
    "        data[f'value_{i}'] = np.random.rand(n_rows)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle('test_data_large.pkl')\n",
    "    print(f\"Generated test data: {n_rows} rows, {n_cols} columns\")\n",
    "\n",
    "# キャッシュ実装\n",
    "@lru_cache(maxsize=1)\n",
    "def load_data_lru_cache(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "joblib_memory = Memory('./joblib_cache', verbose=0)\n",
    "@joblib_memory.cache\n",
    "def load_data_joblib(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "diskcache = Cache('./diskcache_cache')\n",
    "def load_data_diskcache(file_path):\n",
    "    key = f'data:{file_path}'\n",
    "    data = diskcache.get(key)\n",
    "    if data is None:\n",
    "        data = pd.read_pickle(file_path)\n",
    "        diskcache.set(key, data)\n",
    "    return data\n",
    "\n",
    "def load_data_no_cache(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "# cachetoolsの改善された実装\n",
    "def get_file_mtime(file_path):\n",
    "    return os.path.getmtime(file_path)\n",
    "\n",
    "ttl_cache = TTLCache(maxsize=1, ttl=3600)  # 1時間のTTL\n",
    "\n",
    "@cached(cache=ttl_cache, key=lambda file_path: (file_path, get_file_mtime(file_path)))\n",
    "def load_data_cachetools(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "# 複雑な操作の例\n",
    "def perform_operation(df):\n",
    "    result = df.groupby('id').agg({\n",
    "        'value_2': 'mean',\n",
    "        'value_3': 'sum',\n",
    "        'value_4': 'max',\n",
    "        'value_5': 'min'\n",
    "    })\n",
    "    return result\n",
    "\n",
    "# パフォーマンス測定関数\n",
    "def measure_performance(load_func, file_path, num_iterations=100):\n",
    "    gc.collect()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_mem = process.memory_info().rss\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        df = load_func(file_path)\n",
    "        result = perform_operation(df)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    end_mem = process.memory_info().rss\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_iterations\n",
    "    mem_used = (end_mem - start_mem) / (1024 * 1024)  # MB単位\n",
    "    \n",
    "    return avg_time, mem_used\n",
    "\n",
    "# メイン実行部分\n",
    "if __name__ == \"__main__\":\n",
    "    # テストデータの生成（初回のみ実行）\n",
    "    # generate_large_test_data()\n",
    "\n",
    "    file_path = 'test_data_large.pkl'\n",
    "    implementations = [\n",
    "        (\"No Cache\", load_data_no_cache),\n",
    "        (\"lru_cache\", load_data_lru_cache),\n",
    "        (\"joblib\", load_data_joblib),\n",
    "        (\"diskcache\", load_data_diskcache),\n",
    "        (\"cachetools\", load_data_cachetools)\n",
    "    ]\n",
    "\n",
    "    print(\"Performance Test Results:\")\n",
    "    print(\"-------------------------\")\n",
    "    for name, func in implementations:\n",
    "        # キャッシュをクリアし、初回ロード時間を測定\n",
    "        if name == \"lru_cache\":\n",
    "            load_data_lru_cache.cache_clear()\n",
    "        elif name == \"joblib\":\n",
    "            joblib_memory.clear()\n",
    "        elif name == \"diskcache\":\n",
    "            diskcache.clear()\n",
    "        elif name == \"cachetools\":\n",
    "            ttl_cache.clear()\n",
    "        \n",
    "        first_load_time, first_mem_usage = measure_performance(func, file_path, 1)\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  First load time: {first_load_time:.4f} seconds\")\n",
    "        print(f\"  First load memory usage: {first_mem_usage:.2f} MB\")\n",
    "        \n",
    "        # 2回目以降のロード時間を測定\n",
    "        cached_load_time, cached_mem_usage = measure_performance(func, file_path)\n",
    "        print(f\"  Cached load time: {cached_load_time:.4f} seconds\")\n",
    "        print(f\"  Cached load memory usage: {cached_mem_usage:.2f} MB\")\n",
    "        print()\n",
    "\n",
    "    # ファイルの更新をシミュレート\n",
    "    print(\"Simulating file update...\")\n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write('dummy')  # ファイルを更新\n",
    "    \n",
    "    print(\"Performance after file update:\")\n",
    "    print(\"-------------------------------\")\n",
    "    for name, func in implementations:\n",
    "        update_load_time, update_mem_usage = measure_performance(func, file_path, 1)\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Load time after update: {update_load_time:.4f} seconds\")\n",
    "        print(f\"  Memory usage after update: {update_mem_usage:.2f} MB\")\n",
    "        print()\n",
    "\n",
    "    # ファイルサイズの確認\n",
    "    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB単位\n",
    "    print(f\"Test data file size: {file_size:.2f} MB\")Performance Test Results:\n",
    "    -------------------------\n",
    "    No Cache:\n",
    "      First load time: 0.0139 seconds\n",
    "      First load memory usage: 22.17 MB\n",
    "    [Memory(location=./joblib_cache/joblib)]: Flushing completely the cache\n",
    "      Cached load time: 0.0039 seconds\n",
    "      Cached load memory usage: 22.43 MB\n",
    "    \n",
    "    lru_cache:\n",
    "      First load time: 0.0052 seconds\n",
    "      First load memory usage: 0.00 MB\n",
    "      Cached load time: 0.0015 seconds\n",
    "      Cached load memory usage: 0.00 MB\n",
    "    \n",
    "    joblib:\n",
    "      First load time: 0.0348 seconds\n",
    "      First load memory usage: 15.98 MB\n",
    "      Cached load time: 0.0057 seconds\n",
    "      Cached load memory usage: 6.57 MB\n",
    "    \n",
    "    diskcache:\n",
    "      First load time: 0.0688 seconds\n",
    "      First load memory usage: 0.02 MB\n",
    "      Cached load time: 0.0036 seconds\n",
    "      Cached load memory usage: 0.00 MB\n",
    "    \n",
    "    cachetools:\n",
    "      First load time: 0.0058 seconds\n",
    "      First load memory usage: 0.00 MB\n",
    "      Cached load time: 0.0015 seconds\n",
    "      Cached load memory usage: 0.00 MB\n",
    "    \n",
    "    Simulating file update...\n",
    "    Performance after file update:\n",
    "    -------------------------------\n",
    "    No Cache:\n",
    "      Load time after update: 0.0056 seconds\n",
    "      Memory usage after update: 0.00 MB\n",
    "    \n",
    "    lru_cache:\n",
    "      Load time after update: 0.0016 seconds\n",
    "      Memory usage after update: 0.00 MB\n",
    "    \n",
    "    joblib:\n",
    "      Load time after update: 0.0071 seconds\n",
    "      Memory usage after update: 0.00 MB\n",
    "    \n",
    "    diskcache:\n",
    "      Load time after update: 0.0050 seconds\n",
    "      Memory usage after update: 0.00 MB\n",
    "    \n",
    "    cachetools:\n",
    "      Load time after update: 0.0052 seconds\n",
    "      Memory usage after update: 0.00 MB\n",
    "    \n",
    "    Test data file size: 22.89 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
